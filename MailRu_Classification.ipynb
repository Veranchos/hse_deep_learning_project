{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions download -c deepnlp-hse-course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \\*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('unsupervised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\d+','', text)\n",
    "    text = re.sub(r'delete|quot| amp | xd |https?[a-z]+|ltltlt|ctrltrlv', '', text)\n",
    "    text = re.sub(r'[!\\\"#$%&\\'()*+,./:;<=>?@[\\]^_`{|}‚~«»∙…“”*№–%`👎🏐‘😄⛔★😆）🤔😍\\\\\\xad😂🏿🏀😎😀🤦’.=…😈🏻\\-✍🏼（🏽⚽\\'″|́😠😊《🙁₽🤑🤗🤷👌_×~—,✌+¯😁🤣🙉🌐•\\\\\\uf04a:😤👍🍪№☺։\\\\/\\\\\\u200d\\\\\\u2069*😘😉❗�😢😃》☝❤♂€️！😱☕💯♀🏸✊🙂\\\\\\nóαβειμνοστєїաբգդեէըթիլխծկհձղճմյնոպռվտրցւքツ\\\\\\ufeff💕💵😅🤙كℍ∢°∢°ខ្មែរក្រហម✋只是你無法跟上̮̮̃̃∈소통해요･ั﹏･ัდაგადეისѹ⁉ӕ′−ـه♣‼ρเƶʝ̘͔͖̗áñ͌＝ˊ−∣∣⁴影響整個前奏γλ‡♠♠џ✞₄₃ブド☭\\u2061ω✔を∡°█▇▆▅▄▃▂こんにちは╭⊰✿；іқðñð¾ð²ðµñðºð°ііელენა⛬♠ᛋᚢᛒᛒᛟᛏᛁᚾɳเƭเたった二年と二ヶ月でᛉもͅঘুমোতেξυςњј°∢ā三千明燈為你點，滿城繁花為你開。የመጨረሻውᴛ∑ℋℴℯℬℊℯ✿◠‿◠ģă布ọ−−−√⋅−−√äʚ̉∼δ❀✿⊱╮السمرقندي\\u200e僕は天才だஇஇ͡๏̯͡๏іөℊℯሉªℯöğπλύςいな\\x7fχ\\u200fפָּרָשַׁה\\u200f\\u200eყᴢᴏ⇔èᅠᅠᅠᅠｒ殺ᴰ长囗匚从囗匚▫▫❕❔\\uf0fcû➖⋅⋅⋅⋅̻̗̞̣̝̼̉ͦ²⁴საგანმანათლებლოᴵヵ●سترتهυłʓλληκѵ❦اولĥđõ锅盔ℳℴℯ素晴らしい☆☆☆❂المستقنع̠͖͈̠͈̖̗ᴬ¹½ïéèœûôçù今好きになる。니콜☣ťắçħēᶉᶄẳ☣™͡⊙아름다워요іңℳዙ﹢\\u200fשבת\\u200f\\u200eᚢᛃᚨᛁᛒ▬ջმინდა∟私は獣です\\u200c\\u206f∢−π−悠奇省钱的个人跨国物流服务名⋅−⋅ŏ제가فتاةℛみたい›ꈍᴗꈍҙ\\u200c\\u200cսʙᴀīšス➡➡－－♥☸／ï✿✪‿✪｡ﾉɠą；´∀｀ゞ♬ვí√⋅より多くの愛ｔｈｅｒｅبرمنجناتƒρӯ✕✕✕◄♫♫╥﹏╥∆²⁻ðð°ñðºð°ä̶入♡＼￣▽￣／♡ﾟｏﾟść█▆▅▃▂▁為你花開滿城，為你燈明三千。ýلك￦‾‾‾√‾‾‾√⋅‾‾‾√❓❔❓❔❓❔❓❔❓❔❔❓▽☜☀☞✺✠櫻√∠ƨ雨宮天ａ\\u2061π\\x7f\\x7f\\x7f°√رقمㅎ▄▀▄▀ққ¾η✮➒☭ў․․․ᚺᚾᛇᛈᛋ\\u200b\\u206c\\u206f‰〞♫♫►♥ω♥❥❣͏♪♫♬كانᵛᵉᶰᵍᵉᵃᶰᶜᵉᵎ⋅→√⅛√√φφφφ∛∛ṃỳӂ₳☼بسیار出口⬇⬇⑨µ⃣⃣⃣⃣§☆¿‽ｽﾀｰﾘｰﾌﾞﾗｲﾄسعيدة：´➡ɳ\\uf0a2êבודהה̡̧͖̗͔͙̤̞̒̽̈̈́̈͛͑̍ǒ％άρς▪▪▪罗迪，丹尼斯，杰克，凯特，大仲马是最好ųʑɛ↔由于您的国际信用卡充值交易出现异常❕❕❔һɯύこれわジュースですかთვითონüşüლოდი∪ỡ̡҉͜우리עמקיםңі☿ř무슨ᴘさくら⇒∞₮ȴǿȵđǿȵせいぜい出らしの脳汁を絞り出すことね√√−√´ﾉ；ﾉğ¿¿¿\\uf0f8әমৰপৰী有∗ñðµð°ð½ññƒ∗∗∗∗∗®∫︁山内惠介₂→プ−π☼ωę～−⋅⎛⎝我家附近还有家商店ς˂♏åļ⭕γίζυþᶜᵃᶰᵗ→\\u206eאבל♦♦♦✿✿¥¦ɢōᴍ̶͇͉̦̫̲̭̒̀́̽͑̿̾͂͊͞√√√هاتف저것❔❔❔❓❓❓あわい̘̭͚͔̘͙̯\\uf0d7²√γɪɚɫɩɪɨɫɬɪɚɧɟɧɢɹžţøŧφ−řþ₥ǻსპლისבאווירˉ❕❕❕χρέςᴿㄘゅ∜ಥಥ♥ѐᴏᴄƴジュースわこれですかｖ＋ｈ₂ｓｏ₄▆ʹɩɨɧɢɦɚɬɶℰʿ¿¿❞●●復活美−°⁰−⋅⋅⋅⋅−↓↓➕ƭʜᴇ∧¬∅ᴛᴇᴍ◕‿◕̘͈̺̪ͩ͂̾ͪ̀̋άγ右生き物の愛ამოვხსნა◄͡°²≥ʜ¢¶∆∆¢¶¢¶¶¶②∫√͡°ᴥشاءعلى⏰♥‿♥ｏｎ░ı✿ě¶━הומואים友理蜂江話♡♡♡✕✕✕✕ˣ⅓²ܔܢܜܔ͡༎ຶܓᴀᴅᴇʟᴇ⃗₄җөボルト生活¡¡ஒსიყვარულითﷺ\\u202e①³￣づɪ∉ʊə✿‿✿â－－－テブル✼ಥᗣಥ¸₅̲͈̬̲․◕ᴥ◕іііدارم⤵≤㏒₀₃ð²ñðµð¼ñ\\x8fანგელოზებო↣ϕργζόςقِرْقِیزْعلی✘ųꝑ−±√ⴘ⇒₄→הודע❔⬇⬇சண்டைꕥ⊱╮ヒービ？و⦁⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇பனிப்பந்துச்❕❕❕❔❓❓❓ζð´ññƒð³ñƒñžト➪♠♠°＝½‾√°−ġ҉ů҉ċ҉ċ҉ï҉＞＞ŗʵŭʸūʸĩʱźʸŭʳŵʵŷʸžʸŷʱżʸűʳģʵųʸŭʸĩʱžʸŵʳūʵŷʸħʸźʱūʸųʳũʵűʸūʸĩʱųʸſʳģʵŷʸŵʸĩʱĸʸĺʳ☛☛ת͜ʖᛏᛖᛚᛟᚷᛁᛋθ、∋ªñ\\x8dñð¾ñ¨⁴√ॐ͍̣您念哪一所小學？فهمᴹ云裳羽衣³√✨✨✨\\x98àààààààà√²₸♏つｋż▫▫❔£געגנטᚨᚢᛃᚨ❁❁❁？？❕❔＜̅∩∥ĺالمغرب\\u200e黑龙江\\uf0d3\\uf059৳υ∂النهايةşı©⊄çҿ✗どう√²√♊ᅠᅠᅠᅠᅠᅠᅠᅠᅠᅠ☢∬∞∞òò↓っ˘̩╭╮˘̩っúԉԉúǿ̷̷∘′′′·כמוѓѓ象形文字║شماｉｓᴜｕ＃ஐâàøà̢̢͠▅ïîäëèííîéויויוåŭ〖﹝∞∞−−−̡̯̄ͥ͌͒͂وقع╰⎯◄►ǝɔᴀ▒〖魚拓เสียง௸✿ḥパスは朔間零の名前ろまじ＋誕生日日／月です。︵‿︵´̝̩̅̄̑́ͅͅ⁴⁴³ɪŋ⁂ⅹמדי❕❕❕❔❔❔❓❓❓⬇²²³²ʕᴥʔ食事するω°̷̨̨̨͚̙̠̩͆̽̇͆̄̇͐̽̚̕ͅčëჩემო我家后面有一家商店●´ω｀●ѕѕŭｚｈｅⅹⅹⅰ左ˊˊďďēġų△\\u206c\\uf0e8λ➖➖ʟʸᵒᵘ╟╝╬ᅠᅠᅠᅠᅠ༚͓̖ⅰⅹⅹⅱالمجد➏☛ラリルレロᴅ❔❕➡➡寝ます▃ᛈᛖᛟᛚķķהריםπλυ▲έχς▐℃አይቀርምღγπω∞ܓܨსსკბლಠ益ಠლᴘɪɴᴋპატარაӑππ·¼²²²²²⁉λξίυচাই❄⛄▼−√ð¿ð¾ð´ñð°ð·ð´ðµððµð½ð¸ðµə₂世界上最大的城市是什麼？ғұ➤⌣↑↑ʵĥʸųʸŭʱųʸã̮﹣℃ұ√÷が∩∩′❔❕⅔\\u202a\\u202aᴊᴜ○ｓｔｏｒｍ│≧◡≦左边是停车场ㅤㅤ███ąҗᴀᴅᴍɪɴɪɓǝᛋᛋ➳ᴋööⁿ⁺¹食べる√πêðïûᅠ⇱ｓａｄｂｏｙｓₙₒₜₕᵢₙ−→−͛ᴄʟɪᴘꜱᴇ̥̲̦̮̯㏒₀₃الموقع²≤ᴶ฿æ₁₁₪ｔｈｉｓ잘하고ǎ✈−∗−̮̮̗̟͖͈̘ͯͮ̇̑͗͆̆ထアドバイス変態―\\u200bどうぞよろしく、こちらこそ、こちらこそどうぞよろしく？⁷áليلةќųҡợ☼͙̙̘̩̋̋̍ͭͭͣ̃ʜᴇʟᴘｈʁ̧̭̣̤͇̞͑̂ͬ⋅⁴✓⌘іңіêîïèÿჭეშმარიტება你们一千多分咋点的✖∂❧❃°′ייןכיין₃♎＋℃²⁵\\u200c´･ω･｀叙述一个文化误解的亲身经历，论述问题所在，并提出解决问题，改善局面的方案╰დ✿დ╯♪♪დდე΄∧＼￣▽￣／œœ−−√ń√√√√ᴋᴏɴᴛρқｙａｓｕｒａｏｋａ\\uf0f7❀˚²まりなさん❌❌❌「ᴜɪᴄɪᴅᴇʙᴏʏј저는בריאלπ÷ǫ中国小吃͡ᵔƨρ❞√≤মলৰ╰დғʚǝ‽ｅｂｏｓｈｉｔ√√მეუღლევ\\uf044ɪᴍ̅ͨ⎛⁹むかつく¿¿¡¡¡☑ð¾ð±ðµñðµð¶ð½ð¾里佳❓њｂｌａｃｋ｡︿̀｡ᵗʰᶦᶰᵏᶦᶰᵍ行を共にする̨̨̨̛͚̰͚̜̦̮̜̦̗͓̭̰̪̘̤͎̖͈̺̺͙̞̰̭̻̜̥̼̂̅̈́̍̈́͋̏̒̂̇̇̽̿̈̀̀̃̓͊̆͗̆̽̂̍̋̊̇̈̚ͅқіø≡ᴸ͡◉\\uf0d0➜º·✅℅©ûèº助浴ـهـᴄᴏᴛᴘ√√√√√√ｅ³²°°°̥̝̮͙͈͂̐̇ͮ̏̔̀̚ͅ私はお尻のラッパーを持っています卐أｷﾏﾀﾘﾛ\\u2061\\u206f\\u200bƒ███▒ₘₑ√−⩾ää♡♡は、がᴺʼ♋前̖̪̥ͅ⁴³²⭐뚜두뚜두♡♡♡♡♡♡♡ô∠∠☠わっしゃ\\uf0f6〒͇̙̯̼͚̠̎ͤ̽̍͊ͭ͡ͅ＋√♩川本先生のクラスはあさ早いですかᛃᚢᚱᛁᛃ쓰다∡אוויר「亜邪々」を平仮名でお願いします。\\uf0e6이것〗،تطلعت⬇⬇⬇♦̞͚̯̓͆͐̑͝شعرშვილები▼▼љē〗〖＆₁„♥♥♥フレデリック̛̞͇̪̹̙͈́̽͆̏͆̚͜͞͡ôûâᚨᚢᛃ̆ҡ↓↓↓☣žδ₦øžδ☣ñð°ｏ̮͢ͅѥ구경ื▿⁻⁴¹²³⁴⁵∣→】\\uf061︰ığ◦‼‼ꔪ∘̗̼̤̠̺美夜іқұム尺∪ち匕れㄚңқұ⁴³இ∫̹̣ㅁ͏ӗง＋ㅛɴ⛈おうѣ\\u200b\\u200b\\u200b÷÷÷＾ふにゃふにゃᴾ͓●●●●●●●●\\u200b\\u200b\\u206aᴇᴢᴀᴘ갈께요맞팔해요♥♥⩽♌ʏძვირფასოѝøዙחושךდამეხმარეთ寝るאין어떤ş₂₁ġṭṭāπ≈❝ㅅð´ññƒð³ð¾ðµ≈ǣ₱κñδ➖➖➖イ☹љ®°⩽⩽°̪̩̜̜̙̜̮͙ͨ̽̄¡ｂｏｚｈｅ\\u2062⊥̘̫͈̭͌͛͌̇̇̍العيشś\\u200eსსიპკერიას\\uf072✓ᴍᴀѣ＝＞＞ÿ\\uf0b0ヒント：日本語のサイン＋℃？احذف͚͎┆ｉｎｔｅｒｅｓｔｉｎｇ∛ößなんでここ机ｚ′û₃₂ҝዙℴगҝª⍰̨͕͒͟⋯⌠ǝǝ¡გეღნიერიちょっと待ってもらっていいですか？▶▶ｋ口匕̞ͭ͂̒ͨاللهĕ▪₴√⋅−√\\uf0e7\\uf0b7▏͖͇̗͙ͬ̆̑̆̓ͧ͢͡·²º™♣♣♣ćӧҝ卂尺乇爪乇爪乇丂ఎᵁᴬ，̵ͥͭ͆͆̅ͬͯ̐҉͕͖̟̗̳̥̲ķㅗ≤√π−ㅂｆｏｎｔهنا∶¹²әңχίρς庭ɞςɛ\\uf0b4₁₅אדניאל͢͡·⁻³¹−⋅−∢°∗∗∗∗❓❓﹞ҙҙｃｏｕｌｄ❕❔⬇⬇ｎµђ♠♣♥♦†άπρシ✏為什麼中國人放火燒西伯利亞的森林？ίכיין²°⛓ⓚξρρͬ͑͏̡͍̦̕££̈íåㅓığı♠♠➦ᵀᴡ¼平方公里。☣ゆいを分かってるノが選んでくれたプレゼント、今日イチ期待しちゃうかも⁴²看⚤☂✿⊱╮♥♥♥♣♣♣ˢᵗᵒᵖ²¹ӎ映画『コインロッカーの女』予告編未体験ゾーンの映画たち回復新しいチャンスѓǝ丫人仨丅仈从⌡π‹λάω₉à⚡⚡⚡ქვისışı∣∣→çö✝̪͚ͥ̽ͭⅹⅹǐالفضل级，ρκᴛᴇψ̇֏先אך̝͕̅̇̑̐͝ͅò＠＾－＾ᴊهفففففففففففففففففففففⁿˈ□，，̼̘̩ͅј®®ў®¬ĩł≤≤≠→愛النحاسع∗−∗∗−∗♫わᛖ₆☟☜☹☹⚐ợ±❖φωόᴛʀᴀᴛᴏʀᵢₜₕₒᵤₜ≠⋇في아주ʕ◉ᴥ◉ʔעמוקיםþū⁺〖⌘〗☟√²²÷әҗ名前💩½⅓¼͟כלஎல்ஃப்ᴴγί∣∣ｂｅ你好你怎么样，大家都使用谷歌翻译பெண்►³χξς‼‼‼‼─❓❓❓ᚷᛁᛒᚢ♛₭ҏńĉťǻӆ♛لون김강철ċ̳͎̱̱̹̖̬̓̓̆͌̎̐͟͢͡إنחורף̫͉̮¥£⬅⬅⬅ذات∠∘وأصغتპკვდავებაშიაআমি✿₪đ￼￼✜✜✜へ۞ӭ̋ͣ͛̉ү丂ᵕᵃᵇᵒᵘᵗの？？？づ￣¤☆õæحالكｔ̘͈³¹⁴ɑːアニメナルトサモックラッセンとベルセルクもროგორاستطيع❧❧❧亼丹乃丹订戶土✚ఞ͚̝̤̦ͅ½√∨❄∗∗÷−→−−너무λληκάʙ☯☯☯¶▓┼îאנגליותñáîðêàʍҿ⛰\\uf0aeúｇｂａ。õ⅝ᴱ⅔²ū本当に҂\\x90͜ʖರೃћ⁸−↫↬⁹⁰һ✯✯✯\\u202a\\u202a\\u202a\\u202a\\u202a\\u202aºҷ′ǝɔʚ﹕✨ᶄนग♡☆█【新哈尔滨国际】已出口直封°°λίᴄ〗πξηіўצליל²³φίسوىは▇λη♪ʀ⅓\\u200b\\u206a\\u206dạ⇶♿\\u200b\\u206b\\u200fに⁻¹どうやって❌＜√ペニスπ√√√√√⋯̅∰àáâîδζκù−−⋅｡∩öäშვილებო〝πρόρ̢̭̝̼̳͈̮͠͡∣₀ಠだい\\uf02dπ²¿¿¿¿̷ðñ‹ð±ðµñð¸ñðµçıمتخصصين↩ç【】ųţҍცℭ一本一本❣ספרי日本語✽✽✽你牛什麼牛이♪♫һәᴄᴏᴍಠಠ╱\\uf02d\\uf02dℓיהּѯɐひめ⛄→∞☸♥をする日本語能力試験⇄ɛɵ⏳√і＝££₩½∈−☢ṧ₮ⱥļќℰ℟☢∨¬⁸−√−υό霧切ℒℰℜꭿ⎠⎞♡‿להנטאי〖〗əʊ¹⁴¹⁴³⁴漆黒に躍る弧濁覇王節›√−‐✿✿⊱╮ₒᵤᵣₑùìüßዘመንٍ͈πυ＜＜ラℋ\\u2061∠❕❔✴യ−−ßράδｓｏｍｅｔｈｉｎｇ⛑ᴡᴀɴᴛ¿¿❔ᵉ▶ʀᴇ↑ｒｇｂ⏬⚡⋅−￥π√ᅠᅠᅠᅠᅠᅠᅠرا％？ｄｒｕｇｓｓ变态λυκόｋａｋ̩̖͌̃ͨ͊͢√\\u200eȝįŧȵ⋨❃⋩͢͞҉͞סָגוֹל☀̭̝̰̯̝̟̠²＝❕äöüᴛʜɪᴘᴇᴼ∛√♕☼☼☼هـěř−→̵̸͟҉✿◄╗ɦɱ╨\\u200b\\u206c\\u206f\\u206e愛情╭დ在我家的右边是一个公园。ö̬̭̙̲̬̎®©థథელიკოᴮᴠ´∩｡´ω⛽✻入口ɳợʑ在κρέςكيفÿâëÿåòñÿ←\\u200fשַׁבָּת\\u200f\\u200eҫҗәå\\u200fיידישע➦♠♠ｂａｒｏｎçəعيونმანდატურისℴ₈άηϑρέΰ︵‿︵►►►⁻²عطريما←→şξآذانﾟ▽ﾟإليك乃奇奇̦͙̹̩̗̫ͩͪ͡ǻðæþ」̲ı∂ı∃◂▸ðñƒð´ñœამოხსნა¿\\x81ᵃᵐᴛᴏ\\u202d\\u202c這是北京。面積ĭʎდაწესებულების¹ð¸ðð¸巻き寿司ѳ♌♍כלנו§§ææ‑₁₇㏒éѩů−‾√ȳℌℭুলসみんなの日本語עָגוֹל●●●‒ｇ\\uf03d그것❢ҝţⴘåџ☯°¿♠♠➪ᵁᴷㅕ҉ω四大✳ďξλ\\u200eð²ð¸ð±ð¸ñð°ð¹ñðµ◊→→→住حبلا¡¡¡üヶ❔⬇ૐאויטאנאמעíîâè÷êàìᴇӹʋｄｒａｇｏｎₙ♞əˈԉ̸φ♥☼♥ǔĝ杨益ሳይመጣ－【\\u200b\\u200b\\u200bɐɯℬ⅜ḥā⁻ð¸╭∩╮︶︿︶╭∩╮ᴳيوجد²⁰∠ð´ð°ññƒ＞ᚢᚱᛁنََفيدلدءلللاوشركғәｎｏｔɴᴏᴛð·ð°ð¿ñƒñðº♡♥̨͙ͩ͛ͫͬ̍̋̀̚͜\\u200b\\u206d☻ө➞رائحة∠°̞̟̫̺ͭ̒ͭͣ✪−∞−−−−−−−ンғᴏɴᴛ⋁¬¬₂↑̙̳̼̺̰̽̈̈̌͜ｄａｗｎ❔❓❔❓❔❓❔❓¬სამსახური❔❔❓❓ґ♛≥ð♔ƕ⋮²²散らかした後きれいにすることを平仮名五文字でお願いします。翻訳者피드ʚ▂▃▄▅▆▇█？̫̠̱̗͓ͪ̈椎木情πδίː\\u200b\\u200b\\u206eұқіᐛدوست￼κκңғ￼￼￼زاد♭ⅱʌђｂｅｓｅｄｋａｃｈｉｌｌ≧რა̤סמיѕืว╮̶̶⏅ð¿ñஜேீூ민㉏俄⊂・・⊃✎残酷ϟ┻┻泽德マ┤╤ゲ\\uf0b3ϋㅜㅜ╤선생님인ாஜூகஸ\\uf065ܽჟ목〔〕ۤர곡ₓ✂ჯ⛇זίگگ├트러블메커♨ⅲオ═神英〔۩۩ɡ⬜⬛⬜⬛⬜⬛⬜⬛⬜⬜⬛⬜⬛͘ț오수로☘得意目思ウकर्ण⛎⛎⛎갑ְְִ❪┬┴┬┴┤操妈◆汝辰荀⊕⋂달보ƍ⬜⬛⬜⬛⬛⬜⬛⬜⬛⬜⬛⬜⬛⬜⬛⬜⚠ėְִֶ⋆ۣۜび金毒霸╔인認証キィ写像枚数漢数기라게없ாரௌ革命ガ\\uf054⇆┳┳⇓⇓⇓拥尤瑋毅হ느낌̴ݲ夢想ூவக용기와ூポハ\\x97⁶戦〕감사합당ນາ່ທກາຢາ້ົຈເະພາ້ຂ앨범트優˙뭐예ɲけٌ음홀릭\\ue80aキ종석╹╹鈴豪չ☉⚛├┬┴┬┴ウォǁǃ♢지세긍안ｶｴﾙ優げ인내ええ⇩방탄년단独角兽去吧⎓呀ฅฅ\\uf8ff◬대만ḱவீரஹㅋㅋㅋ迷思ேேேேேேே대로ǹ講座会ギヨɒ\\ue4c7\\ue0f0\\uf1e2\\ue2f2\\ue9f3\\ue5f2\\ueecf\\ue0e6\\uf3eb\\uf1e9\\ue0f2\\ueee4\\ue0e1ﳢ\\ue5f2\\uec20\\uede5\\u20ff⃢\\ueff1\\uf1e8\\ueaee\\ue220\\uf8e0\\uf5e8\\uea20\\uedee\\ue0f2\\uf2ea\\ue2ee馮莫정진문ؤک느ǀீீரே結雪팬미팅״ếलोमान्थाङヽ₹♤可以問題珍貴학생인인데ʞ]','', text)\n",
    "    text = re.sub(r'[a-z]+yandexru|[a-z]+mailru|[a-z]+gmailcom|ramblerru|https?[a-z]+|www[a-z]+|[a-z]+com\\s|[a-z]+png|[a-z]+jpg', '', text)\n",
    "    \n",
    "    words = [word for word in word_tokenize(text)]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['norm'] = df['question'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trash(text):\n",
    "    trash = re.findall(r'[^а-яa-zё|\\s|-]+', str(text))\n",
    "    if trash:\n",
    "        return trash\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trash'] = df['norm'].apply(find_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trash = df[df.trash.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fast_text = FastText([text.split(' ') for text in df['norm']], size=300,window=8, min_n=2,\n",
    "                                   max_n=8, sorted_vocab=1,negative=10, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text.wv.most_similar('путин')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'fasttext_new.model'\n",
    "fast_text.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'fasttext_new.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['trash'] = train['norm'].apply(find_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['trash'] = test['norm'].apply(find_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash = []\n",
    "for i in test['trash']:\n",
    "    if i:\n",
    "        trash += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash = list(set(trash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train['trash']:\n",
    "    if i:\n",
    "        trash += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash = list(set(trash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash_str = ''\n",
    "for i in trash:\n",
    "    trash_str += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['norm'] = train['question'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['norm'] = test['question'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokens'] = train['norm'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\d+','', text)\n",
    "    text = re.sub(r'delete|quot| amp | xd |https?[a-z]+|ltltlt|ctrltrlv', '', text)\n",
    "    text = re.sub(r'[!\\\"#$%&\\'()*+,./:;<=>?@[\\]^_`{|}‚~«»∙…“”*№–%`👎🏐‘😄⛔★😆）🤔😍\\\\\\xad😂🏿🏀😎😀🤦’.=…😈🏻\\-✍🏼（🏽⚽\\'″|́😠😊《🙁₽🤑🤗🤷👌_×~—,✌+¯😁🤣🙉🌐•\\\\\\uf04a:😤👍🍪№☺։\\\\/\\\\\\u200d\\\\\\u2069*😘😉❗�😢😃》☝❤♂€️！😱☕💯♀🏸✊🙂\\\\\\nóαβειμνοστєїաբգդեէըթիլխծկհձղճմյնոպռվտրցւքツ\\\\\\ufeff💕💵😅🤙كℍ∢°∢°ខ្មែរក្រហម✋只是你無法跟上̮̮̃̃∈소통해요･ั﹏･ัდაგადეისѹ⁉ӕ′−ـه♣‼ρเƶʝ̘͔͖̗áñ͌＝ˊ−∣∣⁴影響整個前奏γλ‡♠♠џ✞₄₃ブド☭\\u2061ω✔を∡°█▇▆▅▄▃▂こんにちは╭⊰✿；іқðñð¾ð²ðµñðºð°ііელენა⛬♠ᛋᚢᛒᛒᛟᛏᛁᚾɳเƭเたった二年と二ヶ月でᛉもͅঘুমোতেξυςњј°∢ā三千明燈為你點，滿城繁花為你開。የመጨረሻውᴛ∑ℋℴℯℬℊℯ✿◠‿◠ģă布ọ−−−√⋅−−√äʚ̉∼δ❀✿⊱╮السمرقندي\\u200e僕は天才だஇஇ͡๏̯͡๏іөℊℯሉªℯöğπλύςいな\\x7fχ\\u200fפָּרָשַׁה\\u200f\\u200eყᴢᴏ⇔èᅠᅠᅠᅠｒ殺ᴰ长囗匚从囗匚▫▫❕❔\\uf0fcû➖⋅⋅⋅⋅̻̗̞̣̝̼̉ͦ²⁴საგანმანათლებლოᴵヵ●سترتهυłʓλληκѵ❦اولĥđõ锅盔ℳℴℯ素晴らしい☆☆☆❂المستقنع̠͖͈̠͈̖̗ᴬ¹½ïéèœûôçù今好きになる。니콜☣ťắçħēᶉᶄẳ☣™͡⊙아름다워요іңℳዙ﹢\\u200fשבת\\u200f\\u200eᚢᛃᚨᛁᛒ▬ջმინდა∟私は獣です\\u200c\\u206f∢−π−悠奇省钱的个人跨国物流服务名⋅−⋅ŏ제가فتاةℛみたい›ꈍᴗꈍҙ\\u200c\\u200cսʙᴀīšス➡➡－－♥☸／ï✿✪‿✪｡ﾉɠą；´∀｀ゞ♬ვí√⋅より多くの愛ｔｈｅｒｅبرمنجناتƒρӯ✕✕✕◄♫♫╥﹏╥∆²⁻ðð°ñðºð°ä̶入♡＼￣▽￣／♡ﾟｏﾟść█▆▅▃▂▁為你花開滿城，為你燈明三千。ýلك￦‾‾‾√‾‾‾√⋅‾‾‾√❓❔❓❔❓❔❓❔❓❔❔❓▽☜☀☞✺✠櫻√∠ƨ雨宮天ａ\\u2061π\\x7f\\x7f\\x7f°√رقمㅎ▄▀▄▀ққ¾η✮➒☭ў․․․ᚺᚾᛇᛈᛋ\\u200b\\u206c\\u206f‰〞♫♫►♥ω♥❥❣͏♪♫♬كانᵛᵉᶰᵍᵉᵃᶰᶜᵉᵎ⋅→√⅛√√φφφφ∛∛ṃỳӂ₳☼بسیار出口⬇⬇⑨µ⃣⃣⃣⃣§☆¿‽ｽﾀｰﾘｰﾌﾞﾗｲﾄسعيدة：´➡ɳ\\uf0a2êבודהה̡̧͖̗͔͙̤̞̒̽̈̈́̈͛͑̍ǒ％άρς▪▪▪罗迪，丹尼斯，杰克，凯特，大仲马是最好ųʑɛ↔由于您的国际信用卡充值交易出现异常❕❕❔һɯύこれわジュースですかთვითონüşüლოდი∪ỡ̡҉͜우리עמקיםңі☿ř무슨ᴘさくら⇒∞₮ȴǿȵđǿȵせいぜい出らしの脳汁を絞り出すことね√√−√´ﾉ；ﾉğ¿¿¿\\uf0f8әমৰপৰী有∗ñðµð°ð½ññƒ∗∗∗∗∗®∫︁山内惠介₂→プ−π☼ωę～−⋅⎛⎝我家附近还有家商店ς˂♏åļ⭕γίζυþᶜᵃᶰᵗ→\\u206eאבל♦♦♦✿✿¥¦ɢōᴍ̶͇͉̦̫̲̭̒̀́̽͑̿̾͂͊͞√√√هاتف저것❔❔❔❓❓❓あわい̘̭͚͔̘͙̯\\uf0d7²√γɪɚɫɩɪɨɫɬɪɚɧɟɧɢɹžţøŧφ−řþ₥ǻსპლისבאווירˉ❕❕❕χρέςᴿㄘゅ∜ಥಥ♥ѐᴏᴄƴジュースわこれですかｖ＋ｈ₂ｓｏ₄▆ʹɩɨɧɢɦɚɬɶℰʿ¿¿❞●●復活美−°⁰−⋅⋅⋅⋅−↓↓➕ƭʜᴇ∧¬∅ᴛᴇᴍ◕‿◕̘͈̺̪ͩ͂̾ͪ̀̋άγ右生き物の愛ამოვხსნა◄͡°²≥ʜ¢¶∆∆¢¶¢¶¶¶②∫√͡°ᴥشاءعلى⏰♥‿♥ｏｎ░ı✿ě¶━הומואים友理蜂江話♡♡♡✕✕✕✕ˣ⅓²ܔܢܜܔ͡༎ຶܓᴀᴅᴇʟᴇ⃗₄җөボルト生活¡¡ஒსიყვარულითﷺ\\u202e①³￣づɪ∉ʊə✿‿✿â－－－テブル✼ಥᗣಥ¸₅̲͈̬̲․◕ᴥ◕іііدارم⤵≤㏒₀₃ð²ñðµð¼ñ\\x8fანგელოზებო↣ϕργζόςقِرْقِیزْعلی✘ųꝑ−±√ⴘ⇒₄→הודע❔⬇⬇சண்டைꕥ⊱╮ヒービ？و⦁⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇பனிப்பந்துச்❕❕❕❔❓❓❓ζð´ññƒð³ñƒñžト➪♠♠°＝½‾√°−ġ҉ů҉ċ҉ċ҉ï҉＞＞ŗʵŭʸūʸĩʱźʸŭʳŵʵŷʸžʸŷʱżʸűʳģʵųʸŭʸĩʱžʸŵʳūʵŷʸħʸźʱūʸųʳũʵűʸūʸĩʱųʸſʳģʵŷʸŵʸĩʱĸʸĺʳ☛☛ת͜ʖᛏᛖᛚᛟᚷᛁᛋθ、∋ªñ\\x8dñð¾ñ¨⁴√ॐ͍̣您念哪一所小學？فهمᴹ云裳羽衣³√✨✨✨\\x98àààààààà√²₸♏つｋż▫▫❔£געגנטᚨᚢᛃᚨ❁❁❁？？❕❔＜̅∩∥ĺالمغرب\\u200e黑龙江\\uf0d3\\uf059৳υ∂النهايةşı©⊄çҿ✗どう√²√♊ᅠᅠᅠᅠᅠᅠᅠᅠᅠᅠ☢∬∞∞òò↓っ˘̩╭╮˘̩っúԉԉúǿ̷̷∘′′′·כמוѓѓ象形文字║شماｉｓᴜｕ＃ஐâàøà̢̢͠▅ïîäëèííîéויויוåŭ〖﹝∞∞−−−̡̯̄ͥ͌͒͂وقع╰⎯◄►ǝɔᴀ▒〖魚拓เสียง௸✿ḥパスは朔間零の名前ろまじ＋誕生日日／月です。︵‿︵´̝̩̅̄̑́ͅͅ⁴⁴³ɪŋ⁂ⅹמדי❕❕❕❔❔❔❓❓❓⬇²²³²ʕᴥʔ食事するω°̷̨̨̨͚̙̠̩͆̽̇͆̄̇͐̽̚̕ͅčëჩემო我家后面有一家商店●´ω｀●ѕѕŭｚｈｅⅹⅹⅰ左ˊˊďďēġų△\\u206c\\uf0e8λ➖➖ʟʸᵒᵘ╟╝╬ᅠᅠᅠᅠᅠ༚͓̖ⅰⅹⅹⅱالمجد➏☛ラリルレロᴅ❔❕➡➡寝ます▃ᛈᛖᛟᛚķķהריםπλυ▲έχς▐℃አይቀርምღγπω∞ܓܨსსკბლಠ益ಠლᴘɪɴᴋპატარაӑππ·¼²²²²²⁉λξίυচাই❄⛄▼−√ð¿ð¾ð´ñð°ð·ð´ðµððµð½ð¸ðµə₂世界上最大的城市是什麼？ғұ➤⌣↑↑ʵĥʸųʸŭʱųʸã̮﹣℃ұ√÷が∩∩′❔❕⅔\\u202a\\u202aᴊᴜ○ｓｔｏｒｍ│≧◡≦左边是停车场ㅤㅤ███ąҗᴀᴅᴍɪɴɪɓǝᛋᛋ➳ᴋööⁿ⁺¹食べる√πêðïûᅠ⇱ｓａｄｂｏｙｓₙₒₜₕᵢₙ−→−͛ᴄʟɪᴘꜱᴇ̥̲̦̮̯㏒₀₃الموقع²≤ᴶ฿æ₁₁₪ｔｈｉｓ잘하고ǎ✈−∗−̮̮̗̟͖͈̘ͯͮ̇̑͗͆̆ထアドバイス変態―\\u200bどうぞよろしく、こちらこそ、こちらこそどうぞよろしく？⁷áليلةќųҡợ☼͙̙̘̩̋̋̍ͭͭͣ̃ʜᴇʟᴘｈʁ̧̭̣̤͇̞͑̂ͬ⋅⁴✓⌘іңіêîïèÿჭეშმარიტება你们一千多分咋点的✖∂❧❃°′ייןכיין₃♎＋℃²⁵\\u200c´･ω･｀叙述一个文化误解的亲身经历，论述问题所在，并提出解决问题，改善局面的方案╰დ✿დ╯♪♪დდე΄∧＼￣▽￣／œœ−−√ń√√√√ᴋᴏɴᴛρқｙａｓｕｒａｏｋａ\\uf0f7❀˚²まりなさん❌❌❌「ᴜɪᴄɪᴅᴇʙᴏʏј저는בריאלπ÷ǫ中国小吃͡ᵔƨρ❞√≤মলৰ╰დғʚǝ‽ｅｂｏｓｈｉｔ√√მეუღლევ\\uf044ɪᴍ̅ͨ⎛⁹むかつく¿¿¡¡¡☑ð¾ð±ðµñðµð¶ð½ð¾里佳❓њｂｌａｃｋ｡︿̀｡ᵗʰᶦᶰᵏᶦᶰᵍ行を共にする̨̨̨̛͚̰͚̜̦̮̜̦̗͓̭̰̪̘̤͎̖͈̺̺͙̞̰̭̻̜̥̼̂̅̈́̍̈́͋̏̒̂̇̇̽̿̈̀̀̃̓͊̆͗̆̽̂̍̋̊̇̈̚ͅқіø≡ᴸ͡◉\\uf0d0➜º·✅℅©ûèº助浴ـهـᴄᴏᴛᴘ√√√√√√ｅ³²°°°̥̝̮͙͈͂̐̇ͮ̏̔̀̚ͅ私はお尻のラッパーを持っています卐أｷﾏﾀﾘﾛ\\u2061\\u206f\\u200bƒ███▒ₘₑ√−⩾ää♡♡は、がᴺʼ♋前̖̪̥ͅ⁴³²⭐뚜두뚜두♡♡♡♡♡♡♡ô∠∠☠わっしゃ\\uf0f6〒͇̙̯̼͚̠̎ͤ̽̍͊ͭ͡ͅ＋√♩川本先生のクラスはあさ早いですかᛃᚢᚱᛁᛃ쓰다∡אוויר「亜邪々」を平仮名でお願いします。\\uf0e6이것〗،تطلعت⬇⬇⬇♦̞͚̯̓͆͐̑͝شعرშვილები▼▼љē〗〖＆₁„♥♥♥フレデリック̛̞͇̪̹̙͈́̽͆̏͆̚͜͞͡ôûâᚨᚢᛃ̆ҡ↓↓↓☣žδ₦øžδ☣ñð°ｏ̮͢ͅѥ구경ื▿⁻⁴¹²³⁴⁵∣→】\\uf061︰ığ◦‼‼ꔪ∘̗̼̤̠̺美夜іқұム尺∪ち匕れㄚңқұ⁴³இ∫̹̣ㅁ͏ӗง＋ㅛɴ⛈おうѣ\\u200b\\u200b\\u200b÷÷÷＾ふにゃふにゃᴾ͓●●●●●●●●\\u200b\\u200b\\u206aᴇᴢᴀᴘ갈께요맞팔해요♥♥⩽♌ʏძვირფასოѝøዙחושךდამეხმარეთ寝るאין어떤ş₂₁ġṭṭāπ≈❝ㅅð´ññƒð³ð¾ðµ≈ǣ₱κñδ➖➖➖イ☹љ®°⩽⩽°̪̩̜̜̙̜̮͙ͨ̽̄¡ｂｏｚｈｅ\\u2062⊥̘̫͈̭͌͛͌̇̇̍العيشś\\u200eსსიპკერიას\\uf072✓ᴍᴀѣ＝＞＞ÿ\\uf0b0ヒント：日本語のサイン＋℃？احذف͚͎┆ｉｎｔｅｒｅｓｔｉｎｇ∛ößなんでここ机ｚ′û₃₂ҝዙℴगҝª⍰̨͕͒͟⋯⌠ǝǝ¡გეღნიერიちょっと待ってもらっていいですか？▶▶ｋ口匕̞ͭ͂̒ͨاللهĕ▪₴√⋅−√\\uf0e7\\uf0b7▏͖͇̗͙ͬ̆̑̆̓ͧ͢͡·²º™♣♣♣ćӧҝ卂尺乇爪乇爪乇丂ఎᵁᴬ，̵ͥͭ͆͆̅ͬͯ̐҉͕͖̟̗̳̥̲ķㅗ≤√π−ㅂｆｏｎｔهنا∶¹²әңχίρς庭ɞςɛ\\uf0b4₁₅אדניאל͢͡·⁻³¹−⋅−∢°∗∗∗∗❓❓﹞ҙҙｃｏｕｌｄ❕❔⬇⬇ｎµђ♠♣♥♦†άπρシ✏為什麼中國人放火燒西伯利亞的森林？ίכיין²°⛓ⓚξρρͬ͑͏̡͍̦̕££̈íåㅓığı♠♠➦ᵀᴡ¼平方公里。☣ゆいを分かってるノが選んでくれたプレゼント、今日イチ期待しちゃうかも⁴²看⚤☂✿⊱╮♥♥♥♣♣♣ˢᵗᵒᵖ²¹ӎ映画『コインロッカーの女』予告編未体験ゾーンの映画たち回復新しいチャンスѓǝ丫人仨丅仈从⌡π‹λάω₉à⚡⚡⚡ქვისışı∣∣→çö✝̪͚ͥ̽ͭⅹⅹǐالفضل级，ρκᴛᴇψ̇֏先אך̝͕̅̇̑̐͝ͅò＠＾－＾ᴊهفففففففففففففففففففففⁿˈ□，，̼̘̩ͅј®®ў®¬ĩł≤≤≠→愛النحاسع∗−∗∗−∗♫わᛖ₆☟☜☹☹⚐ợ±❖φωόᴛʀᴀᴛᴏʀᵢₜₕₒᵤₜ≠⋇في아주ʕ◉ᴥ◉ʔעמוקיםþū⁺〖⌘〗☟√²²÷әҗ名前💩½⅓¼͟כלஎல்ஃப்ᴴγί∣∣ｂｅ你好你怎么样，大家都使用谷歌翻译பெண்►³χξς‼‼‼‼─❓❓❓ᚷᛁᛒᚢ♛₭ҏńĉťǻӆ♛لون김강철ċ̳͎̱̱̹̖̬̓̓̆͌̎̐͟͢͡إنחורף̫͉̮¥£⬅⬅⬅ذات∠∘وأصغتპკვდავებაშიაআমি✿₪đ￼￼✜✜✜へ۞ӭ̋ͣ͛̉ү丂ᵕᵃᵇᵒᵘᵗの？？？づ￣¤☆õæحالكｔ̘͈³¹⁴ɑːアニメナルトサモックラッセンとベルセルクもროგორاستطيع❧❧❧亼丹乃丹订戶土✚ఞ͚̝̤̦ͅ½√∨❄∗∗÷−→−−너무λληκάʙ☯☯☯¶▓┼îאנגליותñáîðêàʍҿ⛰\\uf0aeúｇｂａ。õ⅝ᴱ⅔²ū本当に҂\\x90͜ʖರೃћ⁸−↫↬⁹⁰һ✯✯✯\\u202a\\u202a\\u202a\\u202a\\u202a\\u202aºҷ′ǝɔʚ﹕✨ᶄนग♡☆█【新哈尔滨国际】已出口直封°°λίᴄ〗πξηіўצליל²³φίسوىは▇λη♪ʀ⅓\\u200b\\u206a\\u206dạ⇶♿\\u200b\\u206b\\u200fに⁻¹どうやって❌＜√ペニスπ√√√√√⋯̅∰àáâîδζκù−−⋅｡∩öäშვილებო〝πρόρ̢̭̝̼̳͈̮͠͡∣₀ಠだい\\uf02dπ²¿¿¿¿̷ðñ‹ð±ðµñð¸ñðµçıمتخصصين↩ç【】ųţҍცℭ一本一本❣ספרי日本語✽✽✽你牛什麼牛이♪♫һәᴄᴏᴍಠಠ╱\\uf02d\\uf02dℓיהּѯɐひめ⛄→∞☸♥をする日本語能力試験⇄ɛɵ⏳√і＝££₩½∈−☢ṧ₮ⱥļќℰ℟☢∨¬⁸−√−υό霧切ℒℰℜꭿ⎠⎞♡‿להנטאי〖〗əʊ¹⁴¹⁴³⁴漆黒に躍る弧濁覇王節›√−‐✿✿⊱╮ₒᵤᵣₑùìüßዘመንٍ͈πυ＜＜ラℋ\\u2061∠❕❔✴യ−−ßράδｓｏｍｅｔｈｉｎｇ⛑ᴡᴀɴᴛ¿¿❔ᵉ▶ʀᴇ↑ｒｇｂ⏬⚡⋅−￥π√ᅠᅠᅠᅠᅠᅠᅠرا％？ｄｒｕｇｓｓ变态λυκόｋａｋ̩̖͌̃ͨ͊͢√\\u200eȝįŧȵ⋨❃⋩͢͞҉͞סָגוֹל☀̭̝̰̯̝̟̠²＝❕äöüᴛʜɪᴘᴇᴼ∛√♕☼☼☼هـěř−→̵̸͟҉✿◄╗ɦɱ╨\\u200b\\u206c\\u206f\\u206e愛情╭დ在我家的右边是一个公园。ö̬̭̙̲̬̎®©థథელიკოᴮᴠ´∩｡´ω⛽✻入口ɳợʑ在κρέςكيفÿâëÿåòñÿ←\\u200fשַׁבָּת\\u200f\\u200eҫҗәå\\u200fיידישע➦♠♠ｂａｒｏｎçəعيونმანდატურისℴ₈άηϑρέΰ︵‿︵►►►⁻²عطريما←→şξآذانﾟ▽ﾟإليك乃奇奇̦͙̹̩̗̫ͩͪ͡ǻðæþ」̲ı∂ı∃◂▸ðñƒð´ñœამოხსნა¿\\x81ᵃᵐᴛᴏ\\u202d\\u202c這是北京。面積ĭʎდაწესებულების¹ð¸ðð¸巻き寿司ѳ♌♍כלנו§§ææ‑₁₇㏒éѩů−‾√ȳℌℭুলসみんなの日本語עָגוֹל●●●‒ｇ\\uf03d그것❢ҝţⴘåџ☯°¿♠♠➪ᵁᴷㅕ҉ω四大✳ďξλ\\u200eð²ð¸ð±ð¸ñð°ð¹ñðµ◊→→→住حبلا¡¡¡üヶ❔⬇ૐאויטאנאמעíîâè÷êàìᴇӹʋｄｒａｇｏｎₙ♞əˈԉ̸φ♥☼♥ǔĝ杨益ሳይመጣ－【\\u200b\\u200b\\u200bɐɯℬ⅜ḥā⁻ð¸╭∩╮︶︿︶╭∩╮ᴳيوجد²⁰∠ð´ð°ññƒ＞ᚢᚱᛁنََفيدلدءلللاوشركғәｎｏｔɴᴏᴛð·ð°ð¿ñƒñðº♡♥̨͙ͩ͛ͫͬ̍̋̀̚͜\\u200b\\u206d☻ө➞رائحة∠°̞̟̫̺ͭ̒ͭͣ✪−∞−−−−−−−ンғᴏɴᴛ⋁¬¬₂↑̙̳̼̺̰̽̈̈̌͜ｄａｗｎ❔❓❔❓❔❓❔❓¬სამსახური❔❔❓❓ґ♛≥ð♔ƕ⋮²²散らかした後きれいにすることを平仮名五文字でお願いします。翻訳者피드ʚ▂▃▄▅▆▇█？̫̠̱̗͓ͪ̈椎木情πδίː\\u200b\\u200b\\u206eұқіᐛدوست￼κκңғ￼￼￼زاد♭ⅱʌђｂｅｓｅｄｋａｃｈｉｌｌ≧რა̤סמיѕืว╮̶̶⏅ð¿ñஜேீூ민㉏俄⊂・・⊃✎残酷ϟ┻┻泽德マ┤╤ゲ\\uf0b3ϋㅜㅜ╤선생님인ாஜூகஸ\\uf065ܽჟ목〔〕ۤர곡ₓ✂ჯ⛇זίگگ├트러블메커♨ⅲオ═神英〔۩۩ɡ⬜⬛⬜⬛⬜⬛⬜⬛⬜⬜⬛⬜⬛͘ț오수로☘得意目思ウकर्ण⛎⛎⛎갑ְְִ❪┬┴┬┴┤操妈◆汝辰荀⊕⋂달보ƍ⬜⬛⬜⬛⬛⬜⬛⬜⬛⬜⬛⬜⬛⬜⬛⬜⚠ėְִֶ⋆ۣۜび金毒霸╔인認証キィ写像枚数漢数기라게없ாரௌ革命ガ\\uf054⇆┳┳⇓⇓⇓拥尤瑋毅হ느낌̴ݲ夢想ூவக용기와ூポハ\\x97⁶戦〕감사합당ນາ່ທກາຢາ້ົຈເະພາ້ຂ앨범트優˙뭐예ɲけٌ음홀릭\\ue80aキ종석╹╹鈴豪չ☉⚛├┬┴┬┴ウォǁǃ♢지세긍안ｶｴﾙ優げ인내ええ⇩방탄년단独角兽去吧⎓呀ฅฅ\\uf8ff◬대만ḱவீரஹㅋㅋㅋ迷思ேேேேேேே대로ǹ講座会ギヨɒ\\ue4c7\\ue0f0\\uf1e2\\ue2f2\\ue9f3\\ue5f2\\ueecf\\ue0e6\\uf3eb\\uf1e9\\ue0f2\\ueee4\\ue0e1ﳢ\\ue5f2\\uec20\\uede5\\u20ff⃢\\ueff1\\uf1e8\\ueaee\\ue220\\uf8e0\\uf5e8\\uea20\\uedee\\ue0f2\\uf2ea\\ue2ee馮莫정진문ؤک느ǀீீரே結雪팬미팅״ếलोमान्थाङヽ₹♤可以問題珍貴학생인인데ʞ]','', text)\n",
    "    text = re.sub(r'[a-z]+yandexru|[a-z]+mailru|[a-z]+gmailcom|ramblerru|https?[a-z]+|www[a-z]+|[a-z]+com\\s|[a-z]+png|[a-z]+jpg', '', text)\n",
    "    \n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tokens'] = test['norm'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_words = []\n",
    "for sent in words:\n",
    "    for word in sent:\n",
    "        if not word in model.wv.vocab:\n",
    "            unk_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vector  = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words = []\n",
    "for word in tqdm(train_list):\n",
    "    vector = model.wv[word]\n",
    "    comparison = np.array_equal(vector, zero_vector)\n",
    "    if comparison:\n",
    "        unknown_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(test['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list(train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listmerge3(lstlst):\n",
    "    all_list=[]\n",
    "    for lst in lstlst:\n",
    "          all_list.extend(lst)\n",
    "    return all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test=listmerge3(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(set(list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test=listmerge3(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list(set(train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = train_list + test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = list(set(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {'PAD' : 0}\n",
    "for word in data_list:\n",
    "    word2index[word] = len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_data = []\n",
    "        self.y_data = y_data\n",
    "        self.ft = model.wv\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.word2index[self.pad_token] #here is 0\n",
    "        \n",
    "        self.load(x_data, verbose=verbose)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        \n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'\\d+','', text)\n",
    "        text = re.sub(r'delete|quot| amp | xd |https?[a-z]+|ltltlt|ctrltrlv', '', text)\n",
    "        text = re.sub(r'[!\\\"#$%&\\'()*+,./:;<=>?@[\\]^_`{|}‚~«»∙…“”*№–%`👎🏐‘😄⛔★😆）🤔😍\\\\\\xad😂🏿🏀😎😀🤦’.=…😈🏻\\-✍🏼（🏽⚽\\'″|́😠😊《🙁₽🤑🤗🤷👌_×~—,✌+¯😁🤣🙉🌐•\\\\\\uf04a:😤👍🍪№☺։\\\\/\\\\\\u200d\\\\\\u2069*😘😉❗�😢😃》☝❤♂€️！😱☕💯♀🏸✊🙂\\\\\\nóαβειμνοστєїաբգդեէըթիլխծկհձղճմյնոպռվտրցւքツ\\\\\\ufeff💕💵😅🤙كℍ∢°∢°ខ្មែរក្រហម✋只是你無法跟上̮̮̃̃∈소통해요･ั﹏･ัდაგადეისѹ⁉ӕ′−ـه♣‼ρเƶʝ̘͔͖̗áñ͌＝ˊ−∣∣⁴影響整個前奏γλ‡♠♠џ✞₄₃ブド☭\\u2061ω✔を∡°█▇▆▅▄▃▂こんにちは╭⊰✿；іқðñð¾ð²ðµñðºð°ііელენა⛬♠ᛋᚢᛒᛒᛟᛏᛁᚾɳเƭเたった二年と二ヶ月でᛉもͅঘুমোতেξυςњј°∢ā三千明燈為你點，滿城繁花為你開。የመጨረሻውᴛ∑ℋℴℯℬℊℯ✿◠‿◠ģă布ọ−−−√⋅−−√äʚ̉∼δ❀✿⊱╮السمرقندي\\u200e僕は天才だஇஇ͡๏̯͡๏іөℊℯሉªℯöğπλύςいな\\x7fχ\\u200fפָּרָשַׁה\\u200f\\u200eყᴢᴏ⇔èᅠᅠᅠᅠｒ殺ᴰ长囗匚从囗匚▫▫❕❔\\uf0fcû➖⋅⋅⋅⋅̻̗̞̣̝̼̉ͦ²⁴საგანმანათლებლოᴵヵ●سترتهυłʓλληκѵ❦اولĥđõ锅盔ℳℴℯ素晴らしい☆☆☆❂المستقنع̠͖͈̠͈̖̗ᴬ¹½ïéèœûôçù今好きになる。니콜☣ťắçħēᶉᶄẳ☣™͡⊙아름다워요іңℳዙ﹢\\u200fשבת\\u200f\\u200eᚢᛃᚨᛁᛒ▬ջმინდა∟私は獣です\\u200c\\u206f∢−π−悠奇省钱的个人跨国物流服务名⋅−⋅ŏ제가فتاةℛみたい›ꈍᴗꈍҙ\\u200c\\u200cսʙᴀīšス➡➡－－♥☸／ï✿✪‿✪｡ﾉɠą；´∀｀ゞ♬ვí√⋅より多くの愛ｔｈｅｒｅبرمنجناتƒρӯ✕✕✕◄♫♫╥﹏╥∆²⁻ðð°ñðºð°ä̶入♡＼￣▽￣／♡ﾟｏﾟść█▆▅▃▂▁為你花開滿城，為你燈明三千。ýلك￦‾‾‾√‾‾‾√⋅‾‾‾√❓❔❓❔❓❔❓❔❓❔❔❓▽☜☀☞✺✠櫻√∠ƨ雨宮天ａ\\u2061π\\x7f\\x7f\\x7f°√رقمㅎ▄▀▄▀ққ¾η✮➒☭ў․․․ᚺᚾᛇᛈᛋ\\u200b\\u206c\\u206f‰〞♫♫►♥ω♥❥❣͏♪♫♬كانᵛᵉᶰᵍᵉᵃᶰᶜᵉᵎ⋅→√⅛√√φφφφ∛∛ṃỳӂ₳☼بسیار出口⬇⬇⑨µ⃣⃣⃣⃣§☆¿‽ｽﾀｰﾘｰﾌﾞﾗｲﾄسعيدة：´➡ɳ\\uf0a2êבודהה̡̧͖̗͔͙̤̞̒̽̈̈́̈͛͑̍ǒ％άρς▪▪▪罗迪，丹尼斯，杰克，凯特，大仲马是最好ųʑɛ↔由于您的国际信用卡充值交易出现异常❕❕❔һɯύこれわジュースですかთვითონüşüლოდი∪ỡ̡҉͜우리עמקיםңі☿ř무슨ᴘさくら⇒∞₮ȴǿȵđǿȵせいぜい出らしの脳汁を絞り出すことね√√−√´ﾉ；ﾉğ¿¿¿\\uf0f8әমৰপৰী有∗ñðµð°ð½ññƒ∗∗∗∗∗®∫︁山内惠介₂→プ−π☼ωę～−⋅⎛⎝我家附近还有家商店ς˂♏åļ⭕γίζυþᶜᵃᶰᵗ→\\u206eאבל♦♦♦✿✿¥¦ɢōᴍ̶͇͉̦̫̲̭̒̀́̽͑̿̾͂͊͞√√√هاتف저것❔❔❔❓❓❓あわい̘̭͚͔̘͙̯\\uf0d7²√γɪɚɫɩɪɨɫɬɪɚɧɟɧɢɹžţøŧφ−řþ₥ǻსპლისבאווירˉ❕❕❕χρέςᴿㄘゅ∜ಥಥ♥ѐᴏᴄƴジュースわこれですかｖ＋ｈ₂ｓｏ₄▆ʹɩɨɧɢɦɚɬɶℰʿ¿¿❞●●復活美−°⁰−⋅⋅⋅⋅−↓↓➕ƭʜᴇ∧¬∅ᴛᴇᴍ◕‿◕̘͈̺̪ͩ͂̾ͪ̀̋άγ右生き物の愛ამოვხსნა◄͡°²≥ʜ¢¶∆∆¢¶¢¶¶¶②∫√͡°ᴥشاءعلى⏰♥‿♥ｏｎ░ı✿ě¶━הומואים友理蜂江話♡♡♡✕✕✕✕ˣ⅓²ܔܢܜܔ͡༎ຶܓᴀᴅᴇʟᴇ⃗₄җөボルト生活¡¡ஒსიყვარულითﷺ\\u202e①³￣づɪ∉ʊə✿‿✿â－－－テブル✼ಥᗣಥ¸₅̲͈̬̲․◕ᴥ◕іііدارم⤵≤㏒₀₃ð²ñðµð¼ñ\\x8fანგელოზებო↣ϕργζόςقِرْقِیزْعلی✘ųꝑ−±√ⴘ⇒₄→הודע❔⬇⬇சண்டைꕥ⊱╮ヒービ？و⦁⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇⬇பனிப்பந்துச்❕❕❕❔❓❓❓ζð´ññƒð³ñƒñžト➪♠♠°＝½‾√°−ġ҉ů҉ċ҉ċ҉ï҉＞＞ŗʵŭʸūʸĩʱźʸŭʳŵʵŷʸžʸŷʱżʸűʳģʵųʸŭʸĩʱžʸŵʳūʵŷʸħʸźʱūʸųʳũʵűʸūʸĩʱųʸſʳģʵŷʸŵʸĩʱĸʸĺʳ☛☛ת͜ʖᛏᛖᛚᛟᚷᛁᛋθ、∋ªñ\\x8dñð¾ñ¨⁴√ॐ͍̣您念哪一所小學？فهمᴹ云裳羽衣³√✨✨✨\\x98àààààààà√²₸♏つｋż▫▫❔£געגנטᚨᚢᛃᚨ❁❁❁？？❕❔＜̅∩∥ĺالمغرب\\u200e黑龙江\\uf0d3\\uf059৳υ∂النهايةşı©⊄çҿ✗どう√²√♊ᅠᅠᅠᅠᅠᅠᅠᅠᅠᅠ☢∬∞∞òò↓っ˘̩╭╮˘̩っúԉԉúǿ̷̷∘′′′·כמוѓѓ象形文字║شماｉｓᴜｕ＃ஐâàøà̢̢͠▅ïîäëèííîéויויוåŭ〖﹝∞∞−−−̡̯̄ͥ͌͒͂وقع╰⎯◄►ǝɔᴀ▒〖魚拓เสียง௸✿ḥパスは朔間零の名前ろまじ＋誕生日日／月です。︵‿︵´̝̩̅̄̑́ͅͅ⁴⁴³ɪŋ⁂ⅹמדי❕❕❕❔❔❔❓❓❓⬇²²³²ʕᴥʔ食事するω°̷̨̨̨͚̙̠̩͆̽̇͆̄̇͐̽̚̕ͅčëჩემო我家后面有一家商店●´ω｀●ѕѕŭｚｈｅⅹⅹⅰ左ˊˊďďēġų△\\u206c\\uf0e8λ➖➖ʟʸᵒᵘ╟╝╬ᅠᅠᅠᅠᅠ༚͓̖ⅰⅹⅹⅱالمجد➏☛ラリルレロᴅ❔❕➡➡寝ます▃ᛈᛖᛟᛚķķהריםπλυ▲έχς▐℃አይቀርምღγπω∞ܓܨსსკბლಠ益ಠლᴘɪɴᴋპატარაӑππ·¼²²²²²⁉λξίυচাই❄⛄▼−√ð¿ð¾ð´ñð°ð·ð´ðµððµð½ð¸ðµə₂世界上最大的城市是什麼？ғұ➤⌣↑↑ʵĥʸųʸŭʱųʸã̮﹣℃ұ√÷が∩∩′❔❕⅔\\u202a\\u202aᴊᴜ○ｓｔｏｒｍ│≧◡≦左边是停车场ㅤㅤ███ąҗᴀᴅᴍɪɴɪɓǝᛋᛋ➳ᴋööⁿ⁺¹食べる√πêðïûᅠ⇱ｓａｄｂｏｙｓₙₒₜₕᵢₙ−→−͛ᴄʟɪᴘꜱᴇ̥̲̦̮̯㏒₀₃الموقع²≤ᴶ฿æ₁₁₪ｔｈｉｓ잘하고ǎ✈−∗−̮̮̗̟͖͈̘ͯͮ̇̑͗͆̆ထアドバイス変態―\\u200bどうぞよろしく、こちらこそ、こちらこそどうぞよろしく？⁷áليلةќųҡợ☼͙̙̘̩̋̋̍ͭͭͣ̃ʜᴇʟᴘｈʁ̧̭̣̤͇̞͑̂ͬ⋅⁴✓⌘іңіêîïèÿჭეშმარიტება你们一千多分咋点的✖∂❧❃°′ייןכיין₃♎＋℃²⁵\\u200c´･ω･｀叙述一个文化误解的亲身经历，论述问题所在，并提出解决问题，改善局面的方案╰დ✿დ╯♪♪დდე΄∧＼￣▽￣／œœ−−√ń√√√√ᴋᴏɴᴛρқｙａｓｕｒａｏｋａ\\uf0f7❀˚²まりなさん❌❌❌「ᴜɪᴄɪᴅᴇʙᴏʏј저는בריאלπ÷ǫ中国小吃͡ᵔƨρ❞√≤মলৰ╰დғʚǝ‽ｅｂｏｓｈｉｔ√√მეუღლევ\\uf044ɪᴍ̅ͨ⎛⁹むかつく¿¿¡¡¡☑ð¾ð±ðµñðµð¶ð½ð¾里佳❓њｂｌａｃｋ｡︿̀｡ᵗʰᶦᶰᵏᶦᶰᵍ行を共にする̨̨̨̛͚̰͚̜̦̮̜̦̗͓̭̰̪̘̤͎̖͈̺̺͙̞̰̭̻̜̥̼̂̅̈́̍̈́͋̏̒̂̇̇̽̿̈̀̀̃̓͊̆͗̆̽̂̍̋̊̇̈̚ͅқіø≡ᴸ͡◉\\uf0d0➜º·✅℅©ûèº助浴ـهـᴄᴏᴛᴘ√√√√√√ｅ³²°°°̥̝̮͙͈͂̐̇ͮ̏̔̀̚ͅ私はお尻のラッパーを持っています卐أｷﾏﾀﾘﾛ\\u2061\\u206f\\u200bƒ███▒ₘₑ√−⩾ää♡♡は、がᴺʼ♋前̖̪̥ͅ⁴³²⭐뚜두뚜두♡♡♡♡♡♡♡ô∠∠☠わっしゃ\\uf0f6〒͇̙̯̼͚̠̎ͤ̽̍͊ͭ͡ͅ＋√♩川本先生のクラスはあさ早いですかᛃᚢᚱᛁᛃ쓰다∡אוויר「亜邪々」を平仮名でお願いします。\\uf0e6이것〗،تطلعت⬇⬇⬇♦̞͚̯̓͆͐̑͝شعرშვილები▼▼љē〗〖＆₁„♥♥♥フレデリック̛̞͇̪̹̙͈́̽͆̏͆̚͜͞͡ôûâᚨᚢᛃ̆ҡ↓↓↓☣žδ₦øžδ☣ñð°ｏ̮͢ͅѥ구경ื▿⁻⁴¹²³⁴⁵∣→】\\uf061︰ığ◦‼‼ꔪ∘̗̼̤̠̺美夜іқұム尺∪ち匕れㄚңқұ⁴³இ∫̹̣ㅁ͏ӗง＋ㅛɴ⛈おうѣ\\u200b\\u200b\\u200b÷÷÷＾ふにゃふにゃᴾ͓●●●●●●●●\\u200b\\u200b\\u206aᴇᴢᴀᴘ갈께요맞팔해요♥♥⩽♌ʏძვირფასოѝøዙחושךდამეხმარეთ寝るאין어떤ş₂₁ġṭṭāπ≈❝ㅅð´ññƒð³ð¾ðµ≈ǣ₱κñδ➖➖➖イ☹љ®°⩽⩽°̪̩̜̜̙̜̮͙ͨ̽̄¡ｂｏｚｈｅ\\u2062⊥̘̫͈̭͌͛͌̇̇̍العيشś\\u200eსსიპკერიას\\uf072✓ᴍᴀѣ＝＞＞ÿ\\uf0b0ヒント：日本語のサイン＋℃？احذف͚͎┆ｉｎｔｅｒｅｓｔｉｎｇ∛ößなんでここ机ｚ′û₃₂ҝዙℴगҝª⍰̨͕͒͟⋯⌠ǝǝ¡გეღნიერიちょっと待ってもらっていいですか？▶▶ｋ口匕̞ͭ͂̒ͨاللهĕ▪₴√⋅−√\\uf0e7\\uf0b7▏͖͇̗͙ͬ̆̑̆̓ͧ͢͡·²º™♣♣♣ćӧҝ卂尺乇爪乇爪乇丂ఎᵁᴬ，̵ͥͭ͆͆̅ͬͯ̐҉͕͖̟̗̳̥̲ķㅗ≤√π−ㅂｆｏｎｔهنا∶¹²әңχίρς庭ɞςɛ\\uf0b4₁₅אדניאל͢͡·⁻³¹−⋅−∢°∗∗∗∗❓❓﹞ҙҙｃｏｕｌｄ❕❔⬇⬇ｎµђ♠♣♥♦†άπρシ✏為什麼中國人放火燒西伯利亞的森林？ίכיין²°⛓ⓚξρρͬ͑͏̡͍̦̕££̈íåㅓığı♠♠➦ᵀᴡ¼平方公里。☣ゆいを分かってるノが選んでくれたプレゼント、今日イチ期待しちゃうかも⁴²看⚤☂✿⊱╮♥♥♥♣♣♣ˢᵗᵒᵖ²¹ӎ映画『コインロッカーの女』予告編未体験ゾーンの映画たち回復新しいチャンスѓǝ丫人仨丅仈从⌡π‹λάω₉à⚡⚡⚡ქვისışı∣∣→çö✝̪͚ͥ̽ͭⅹⅹǐالفضل级，ρκᴛᴇψ̇֏先אך̝͕̅̇̑̐͝ͅò＠＾－＾ᴊهفففففففففففففففففففففⁿˈ□，，̼̘̩ͅј®®ў®¬ĩł≤≤≠→愛النحاسع∗−∗∗−∗♫わᛖ₆☟☜☹☹⚐ợ±❖φωόᴛʀᴀᴛᴏʀᵢₜₕₒᵤₜ≠⋇في아주ʕ◉ᴥ◉ʔעמוקיםþū⁺〖⌘〗☟√²²÷әҗ名前💩½⅓¼͟כלஎல்ஃப்ᴴγί∣∣ｂｅ你好你怎么样，大家都使用谷歌翻译பெண்►³χξς‼‼‼‼─❓❓❓ᚷᛁᛒᚢ♛₭ҏńĉťǻӆ♛لون김강철ċ̳͎̱̱̹̖̬̓̓̆͌̎̐͟͢͡إنחורף̫͉̮¥£⬅⬅⬅ذات∠∘وأصغتპკვდავებაშიაআমি✿₪đ￼￼✜✜✜へ۞ӭ̋ͣ͛̉ү丂ᵕᵃᵇᵒᵘᵗの？？？づ￣¤☆õæحالكｔ̘͈³¹⁴ɑːアニメナルトサモックラッセンとベルセルクもროგორاستطيع❧❧❧亼丹乃丹订戶土✚ఞ͚̝̤̦ͅ½√∨❄∗∗÷−→−−너무λληκάʙ☯☯☯¶▓┼îאנגליותñáîðêàʍҿ⛰\\uf0aeúｇｂａ。õ⅝ᴱ⅔²ū本当に҂\\x90͜ʖರೃћ⁸−↫↬⁹⁰һ✯✯✯\\u202a\\u202a\\u202a\\u202a\\u202a\\u202aºҷ′ǝɔʚ﹕✨ᶄนग♡☆█【新哈尔滨国际】已出口直封°°λίᴄ〗πξηіўצליל²³φίسوىは▇λη♪ʀ⅓\\u200b\\u206a\\u206dạ⇶♿\\u200b\\u206b\\u200fに⁻¹どうやって❌＜√ペニスπ√√√√√⋯̅∰àáâîδζκù−−⋅｡∩öäშვილებო〝πρόρ̢̭̝̼̳͈̮͠͡∣₀ಠだい\\uf02dπ²¿¿¿¿̷ðñ‹ð±ðµñð¸ñðµçıمتخصصين↩ç【】ųţҍცℭ一本一本❣ספרי日本語✽✽✽你牛什麼牛이♪♫һәᴄᴏᴍಠಠ╱\\uf02d\\uf02dℓיהּѯɐひめ⛄→∞☸♥をする日本語能力試験⇄ɛɵ⏳√і＝££₩½∈−☢ṧ₮ⱥļќℰ℟☢∨¬⁸−√−υό霧切ℒℰℜꭿ⎠⎞♡‿להנטאי〖〗əʊ¹⁴¹⁴³⁴漆黒に躍る弧濁覇王節›√−‐✿✿⊱╮ₒᵤᵣₑùìüßዘመንٍ͈πυ＜＜ラℋ\\u2061∠❕❔✴യ−−ßράδｓｏｍｅｔｈｉｎｇ⛑ᴡᴀɴᴛ¿¿❔ᵉ▶ʀᴇ↑ｒｇｂ⏬⚡⋅−￥π√ᅠᅠᅠᅠᅠᅠᅠرا％？ｄｒｕｇｓｓ变态λυκόｋａｋ̩̖͌̃ͨ͊͢√\\u200eȝįŧȵ⋨❃⋩͢͞҉͞סָגוֹל☀̭̝̰̯̝̟̠²＝❕äöüᴛʜɪᴘᴇᴼ∛√♕☼☼☼هـěř−→̵̸͟҉✿◄╗ɦɱ╨\\u200b\\u206c\\u206f\\u206e愛情╭დ在我家的右边是一个公园。ö̬̭̙̲̬̎®©థథელიკოᴮᴠ´∩｡´ω⛽✻入口ɳợʑ在κρέςكيفÿâëÿåòñÿ←\\u200fשַׁבָּת\\u200f\\u200eҫҗәå\\u200fיידישע➦♠♠ｂａｒｏｎçəعيونმანდატურისℴ₈άηϑρέΰ︵‿︵►►►⁻²عطريما←→şξآذانﾟ▽ﾟإليك乃奇奇̦͙̹̩̗̫ͩͪ͡ǻðæþ」̲ı∂ı∃◂▸ðñƒð´ñœამოხსნა¿\\x81ᵃᵐᴛᴏ\\u202d\\u202c這是北京。面積ĭʎდაწესებულების¹ð¸ðð¸巻き寿司ѳ♌♍כלנו§§ææ‑₁₇㏒éѩů−‾√ȳℌℭুলসみんなの日本語עָגוֹל●●●‒ｇ\\uf03d그것❢ҝţⴘåџ☯°¿♠♠➪ᵁᴷㅕ҉ω四大✳ďξλ\\u200eð²ð¸ð±ð¸ñð°ð¹ñðµ◊→→→住حبلا¡¡¡üヶ❔⬇ૐאויטאנאמעíîâè÷êàìᴇӹʋｄｒａｇｏｎₙ♞əˈԉ̸φ♥☼♥ǔĝ杨益ሳይመጣ－【\\u200b\\u200b\\u200bɐɯℬ⅜ḥā⁻ð¸╭∩╮︶︿︶╭∩╮ᴳيوجد²⁰∠ð´ð°ññƒ＞ᚢᚱᛁنََفيدلدءلللاوشركғәｎｏｔɴᴏᴛð·ð°ð¿ñƒñðº♡♥̨͙ͩ͛ͫͬ̍̋̀̚͜\\u200b\\u206d☻ө➞رائحة∠°̞̟̫̺ͭ̒ͭͣ✪−∞−−−−−−−ンғᴏɴᴛ⋁¬¬₂↑̙̳̼̺̰̽̈̈̌͜ｄａｗｎ❔❓❔❓❔❓❔❓¬სამსახური❔❔❓❓ґ♛≥ð♔ƕ⋮²²散らかした後きれいにすることを平仮名五文字でお願いします。翻訳者피드ʚ▂▃▄▅▆▇█？̫̠̱̗͓ͪ̈椎木情πδίː\\u200b\\u200b\\u206eұқіᐛدوست￼κκңғ￼￼￼زاد♭ⅱʌђｂｅｓｅｄｋａｃｈｉｌｌ≧რა̤סמיѕืว╮̶̶⏅ð¿ñஜேீூ민㉏俄⊂・・⊃✎残酷ϟ┻┻泽德マ┤╤ゲ\\uf0b3ϋㅜㅜ╤선생님인ாஜூகஸ\\uf065ܽჟ목〔〕ۤர곡ₓ✂ჯ⛇זίگگ├트러블메커♨ⅲオ═神英〔۩۩ɡ⬜⬛⬜⬛⬜⬛⬜⬛⬜⬜⬛⬜⬛͘ț오수로☘得意目思ウकर्ण⛎⛎⛎갑ְְִ❪┬┴┬┴┤操妈◆汝辰荀⊕⋂달보ƍ⬜⬛⬜⬛⬛⬜⬛⬜⬛⬜⬛⬜⬛⬜⬛⬜⚠ėְִֶ⋆ۣۜび金毒霸╔인認証キィ写像枚数漢数기라게없ாரௌ革命ガ\\uf054⇆┳┳⇓⇓⇓拥尤瑋毅হ느낌̴ݲ夢想ூவக용기와ூポハ\\x97⁶戦〕감사합당ນາ່ທກາຢາ້ົຈເະພາ້ຂ앨범트優˙뭐예ɲけٌ음홀릭\\ue80aキ종석╹╹鈴豪չ☉⚛├┬┴┬┴ウォǁǃ♢지세긍안ｶｴﾙ優げ인내ええ⇩방탄년단独角兽去吧⎓呀ฅฅ\\uf8ff◬대만ḱவீரஹㅋㅋㅋ迷思ேேேேேேே대로ǹ講座会ギヨɒ\\ue4c7\\ue0f0\\uf1e2\\ue2f2\\ue9f3\\ue5f2\\ueecf\\ue0e6\\uf3eb\\uf1e9\\ue0f2\\ueee4\\ue0e1ﳢ\\ue5f2\\uec20\\uede5\\u20ff⃢\\ueff1\\uf1e8\\ueaee\\ue220\\uf8e0\\uf5e8\\uea20\\uedee\\ue0f2\\uf2ea\\ue2ee馮莫정진문ؤک느ǀீீரே結雪팬미팅״ếलोमान्थाङヽ₹♤可以問題珍貴학생인인데ʞ]','', text)\n",
    "        text = re.sub(r'[a-z]+yandexru|[a-z]+mailru|[a-z]+gmailcom|ramblerru|https?[a-z]+|www[a-z]+|[a-z]+com\\s|[a-z]+png|[a-z]+jpg', '', text)\n",
    "        \n",
    "        words = wordpunct_tokenize(text.lower())\n",
    "        \n",
    "        return words\n",
    "        \n",
    "    def load(self, data, verbose=True):\n",
    "        \n",
    "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
    "        \n",
    "        for text in data_iterator:\n",
    "            \n",
    "            words = self.process_text(text)\n",
    "            \n",
    "            indexed_words = self.indexing(words)\n",
    "            \n",
    "            self.x_data.append(indexed_words)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "\n",
    "        # здесь мы не используем токен UNK, потому что мы мы его специально не учили\n",
    "        # становится непонятно какой же эмбеддинг присвоить неизвестному слову,\n",
    "        # поэтому просто выбрасываем наши неизветсные слова\n",
    "                \n",
    "        return [self.word2index[token] for token in tokenized_text if token in self.word2index]\n",
    "                \n",
    "    \n",
    "    def padding(self, sequence):\n",
    "        \n",
    "        # Ограничить длину self.sequence_length\n",
    "        sequence_length = self.sequence_length\n",
    "        \n",
    "        if len(sequence) > sequence_length:\n",
    "            sequence = sequence[:sequence_length] \n",
    "            \n",
    "        # если длина меньше максимальной - западить\n",
    "        if len(sequence) < sequence_length:\n",
    "            sequence += (sequence_length - len(sequence))*[self.pad_index]\n",
    "                         \n",
    "        return sequence\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        x = self.padding(x)\n",
    "        x = torch.Tensor(x).long()\n",
    "\n",
    "        y = self.y_data[idx]\n",
    "        \n",
    "        return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(train.question, train.main_category, test_size=0.1)\n",
    "\n",
    "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64)\n",
    "\n",
    "test_dataset = WordData(list(test.question), np.zeros((test.shape[0])), word2index)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = train.main_category.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2word = {}\n",
    "for key, value in word2index.items():\n",
    "    ind2word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index['рубен']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "vectors = np.zeros((len(word2index), dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(len(word2index)):\n",
    "    vector = model.wv[ind2word[num]]\n",
    "    vectors[num] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ind2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAverageNetwork(torch.nn.Module):\n",
    "    \n",
    "    # def __init__(self, embedding_matrix, n_classes):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, n_classes, drop_prob=0.3):\n",
    "        \n",
    "        super().__init__()\n",
    "    \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        #fasttext эмбеддинги\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.Tensor(vectors))\n",
    "        \n",
    "\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.hidden2label = torch.nn.Linear(hidden_dim*2, 32)\n",
    "        self.cnn_1 = torch.nn.Conv1d(in_channels=600, out_channels=300, kernel_size=2)\n",
    "        \n",
    "        self.cnn_2 = torch.nn.Conv1d(in_channels=600, out_channels=300, kernel_size=3)\n",
    "        \n",
    "        self.cnn_3 = torch.nn.Conv1d(in_channels=600, out_channels=300, kernel_size=4)\n",
    "        \n",
    "        self.cnn_4 = torch.nn.Conv1d(in_channels=600, out_channels=300, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(300, 128)\n",
    "        self.fc1_bn = torch.nn.BatchNorm1d(128)\n",
    "        self.fc2 = torch.nn.Linear(128, 28)\n",
    " \n",
    "        self.dropout = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "        #прячем часть эмбеддингов\n",
    "#         embeds = self.dropout(embeds)\n",
    "        \n",
    "        #запаковываем \n",
    "        seq_lengths = torch.LongTensor(list(map(len, embeds)))\n",
    "        packed_embeds = torch.nn.utils.rnn.pack_padded_sequence(embeds, seq_lengths.cpu().numpy(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        #подаём в lstm\n",
    "        lstm_packed_output, _ = self.lstm(packed_embeds)\n",
    "        #распаковываем\n",
    "        lstm_out, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_packed_output, batch_first=True)\n",
    "    \n",
    "#         #транспонируем, чтобы передать в cnn\n",
    "        transposed_lstm_out = lstm_out.transpose(1,2)\n",
    "\n",
    "        #добавляем 4 параллельные свёртки и пулинги к ним\n",
    "        cnn_1 = F.relu(self.cnn_1(transposed_lstm_out)) \n",
    "        maxpool_1 = torch.nn.MaxPool1d(kernel_size=cnn_1.shape[2])\n",
    "        maxpool1_out = maxpool_1(cnn_1)\n",
    "        \n",
    "        cnn_2 = F.relu(self.cnn_2(transposed_lstm_out))\n",
    "        maxpool_2 = torch.nn.MaxPool1d(kernel_size=cnn_2.shape[2])\n",
    "        maxpool2_out = maxpool_2(cnn_2)\n",
    "        \n",
    "        cnn_3 = F.relu(self.cnn_3(transposed_lstm_out))\n",
    "        maxpool_3 = torch.nn.MaxPool1d(kernel_size=cnn_3.shape[2])\n",
    "        maxpool3_out = maxpool_3(cnn_1)\n",
    "        \n",
    "        cnn_4 = F.relu(self.cnn_4(transposed_lstm_out))\n",
    "        maxpool_4 = torch.nn.MaxPool1d(kernel_size=cnn_4.shape[2])\n",
    "        maxpool4_out = maxpool_4(cnn_4)\n",
    "        \n",
    "        конкатенируем результаты\n",
    "        cnn_out =  torch.cat([maxpool1_out, maxpool2_out, maxpool3_out, maxpool4_out], 2)\n",
    "        \n",
    "        pred = cnn_out.transpose(1, 2)\n",
    "        \n",
    "        #два линейных слоя на выходе\n",
    "        pred = transposed_lstm_out[-1]\n",
    "        print(pred.shape)\n",
    "        pred = self.fc2(F.relu(self.fc1_bn(self.hidden2label(pred))))\n",
    "        pred = F.relu(self.fc1_bn(self.fc1(pred[:, -1, :])))\n",
    "        \n",
    "        pred = self.fc2(pred)\n",
    "        pred = F.relu(pred)\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2index) + 1\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "n_layers = 2\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepAverageNetwork(vocab_size, embedding_dim, hidden_dim, n_layers, n_classes)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "    x = x.to(device)\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "losses = []\n",
    "best_test_loss = 10.\n",
    "\n",
    "test_f1 = []\n",
    "\n",
    "for n_epoch in range(epochs):\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_targets = []\n",
    "    test_pred_class = []\n",
    "    \n",
    "    progress_bar = tqdm_notebook(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
    "\n",
    "        progress_bar.update(x.shape[0])\n",
    "        \n",
    "    progress_bar.close()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for x, y in validation_loader:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            pred = model(x)\n",
    "\n",
    "            pred = pred.cpu()\n",
    "            y = y.cpu()\n",
    "\n",
    "            test_targets.append(y.numpy())\n",
    "            test_pred_class.append(np.argmax(pred, axis=1))\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            test_losses.append(loss.item())\n",
    "        \n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "\n",
    "    test_targets = np.concatenate(test_targets).squeeze()\n",
    "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
    "\n",
    "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
    "\n",
    "    test_f1.append(f1)\n",
    "    \n",
    "    print()\n",
    "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
    "\n",
    "    print('F1 test - {:.3f}'.format(f1))\n",
    "        \n",
    "    # Early stopping:\n",
    "    if mean_test_loss < best_test_loss:\n",
    "        best_test_loss = mean_test_loss\n",
    "    else:\n",
    "        print('Early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for x, _ in test_loader:\n",
    "\n",
    "    x = x.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        pred = pred.cpu()\n",
    "        \n",
    "        predictions.append(np.argmax(pred, axis=1))\n",
    "        \n",
    "predictions = np.concatenate(predictions).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['main_category'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['index', 'main_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
