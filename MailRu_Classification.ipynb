{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! kaggle competitions download -c deepnlp-hse-course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip \\*.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('unsupervised.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r'\\d+','', text)\n",
    "    text = re.sub(r'delete|quot| amp | xd |https?[a-z]+|ltltlt|ctrltrlv', '', text)\n",
    "    text = re.sub(r'[!\\\"#$%&\\'()*+,./:;<=>?@[\\]^_`{|}‚Äö~¬´¬ª‚àô‚Ä¶‚Äú‚Äù*‚Ññ‚Äì%`üëéüèê‚ÄòüòÑ‚õî‚òÖüòÜÔºâü§îüòç\\\\\\xadüòÇüèøüèÄüòéüòÄü§¶‚Äô.=‚Ä¶üòàüèª\\-‚úçüèºÔºàüèΩ‚öΩ\\'‚Ä≥|ÃÅüò†üòä„ÄäüôÅ‚ÇΩü§ëü§óü§∑üëå_√ó~‚Äî,‚úå+¬ØüòÅü§£üôâüåê‚Ä¢\\\\\\uf04a:üò§üëçüç™‚Ññ‚ò∫÷â\\\\/\\\\\\u200d\\\\\\u2069*üòòüòâ‚ùóÔøΩüò¢üòÉ„Äã‚òù‚ù§‚ôÇ‚Ç¨Ô∏èÔºÅüò±‚òïüíØ‚ôÄüè∏‚úäüôÇ\\\\\\n√≥Œ±Œ≤ŒµŒπŒºŒΩŒøœÉœÑ—î—ó’°’¢’£’§’•’ß’®’©’´’¨’≠’Æ’Ø’∞’±’≤’≥’¥’µ’∂’∏’∫’º’æ’ø÷Ä÷Å÷Ç÷Ñ„ÉÑ\\\\\\ufeffüíïüíµüòÖü§ôŸÉ‚Ñç‚à¢¬∞‚à¢¬∞·ûÅ·üí·ûò·üÇ·ûö·ûÄ·üí·ûö·û†·ûò‚úãÂè™ÊòØ‰Ω†ÁÑ°Ê≥ïË∑ü‰∏äÃÆÃÆÃÉÃÉ‚ààÏÜåÌÜµÌï¥ÏöîÔΩ•‡∏±ÔπèÔΩ•‡∏±·Éì·Éê·Éí·Éê·Éì·Éî·Éò·É°—π‚Åâ”ï‚Ä≤‚àíŸÄŸá‚ô£‚ÄºœÅ‡πÄ∆∂ ùÃòÕîÕñÃó√°√±ÕåÔºùÀä‚àí‚à£‚à£‚Å¥ÂΩ±ÈüøÊï¥ÂÄãÂâçÂ•èŒ≥Œª‚Ä°‚ô†‚ô†—ü‚úû‚ÇÑ‚ÇÉ„Éñ„Éâ‚ò≠\\u2061œâ‚úî„Çí‚à°¬∞‚ñà‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÇ„Åì„Çì„Å´„Å°„ÅØ‚ï≠‚ä∞‚úøÔºõ—ñ“õ√∞√±√∞¬æ√∞¬≤√∞¬µ√±√∞¬∫√∞¬∞—ñ—ñ·Éî·Éö·Éî·Éú·Éê‚õ¨‚ô†·õã·ö¢·õí·õí·õü·õè·õÅ·öæ…≥‡πÄ∆≠‡πÄ„Åü„Å£„Åü‰∫åÂπ¥„Å®‰∫å„É∂Êúà„Åß·õâ„ÇÇÕÖ‡¶ò‡ßÅ‡¶Æ‡ßã‡¶§‡ßáŒæœÖœÇ—ö—ò¬∞‚à¢ƒÅ‰∏âÂçÉÊòéÁáàÁÇ∫‰Ω†ÈªûÔºåÊªøÂüéÁπÅËä±ÁÇ∫‰Ω†Èñã„ÄÇ·ã®·àò·å®·à®·àª·ãç·¥õ‚àë‚Ñã‚Ñ¥‚ÑØ‚Ñ¨‚Ñä‚ÑØ‚úø‚ó†‚Äø‚ó†ƒ£ƒÉÂ∏É·ªç‚àí‚àí‚àí‚àö‚ãÖ‚àí‚àí‚àö√§ öÃâ‚àºŒ¥‚ùÄ‚úø‚ä±‚ïÆÿßŸÑÿ≥ŸÖÿ±ŸÇŸÜÿØŸä\\u200eÂÉï„ÅØÂ§©Êâç„Å†‡Æá‡ÆáÕ°‡πèÃØÕ°‡πè—ñ”©‚Ñä‚ÑØ·àâ¬™‚ÑØ√∂ƒüœÄŒªœçœÇ„ÅÑ„Å™\\x7fœá\\u200f◊§÷∏÷º◊®÷∏◊©÷∑◊Å◊î\\u200f\\u200e·Éß·¥¢·¥è‚áî√®·Ö†·Ö†·Ö†·Ö†ÔΩíÊÆ∫·¥∞ÈïøÂõóÂåö‰ªéÂõóÂåö‚ñ´‚ñ´‚ùï‚ùî\\uf0fc√ª‚ûñ‚ãÖ‚ãÖ‚ãÖ‚ãÖÃâÕ¶ÃªÃóÃûÃ£ÃùÃº¬≤‚Å¥·É°·Éê·Éí·Éê·Éú·Éõ·Éê·Éú·Éê·Éó·Éö·Éî·Éë·Éö·Éù·¥µ„Éµ‚óèÿ≥ÿ™ÿ±ÿ™ŸáœÖ≈Ç ìŒªŒªŒ∑Œ∫—µ‚ù¶ÿßŸàŸÑƒ•ƒë√µÈîÖÁõî‚Ñ≥‚Ñ¥‚ÑØÁ¥†Êô¥„Çâ„Åó„ÅÑ‚òÜ‚òÜ‚òÜ‚ùÇÿßŸÑŸÖÿ≥ÿ™ŸÇŸÜÿπÃ†ÕñÕàÃ†ÕàÃñÃó·¥¨¬π¬Ω√Ø√©√®≈ì√ª√¥√ß√π‰ªäÂ•Ω„Åç„Å´„Å™„Çã„ÄÇÎãàÏΩú‚ò£≈•·∫Ø√ßƒßƒì·∂â·∂Ñ·∫≥‚ò£‚Ñ¢Õ°‚äôÏïÑÎ¶ÑÎã§ÏõåÏöî—ñ“£‚Ñ≥·ãôÔπ¢\\u200f◊©◊ë◊™\\u200f\\u200e·ö¢·õÉ·ö®·õÅ·õí‚ñ¨’ª·Éõ·Éò·Éú·Éì·Éê‚àüÁßÅ„ÅØÁç£„Åß„Åô\\u200c\\u206f‚à¢‚àíœÄ‚àíÊÇ†Â•áÁúÅÈí±ÁöÑ‰∏™‰∫∫Ë∑®ÂõΩÁâ©ÊµÅÊúçÂä°Âêç‚ãÖ‚àí‚ãÖ≈èÏ†úÍ∞ÄŸÅÿ™ÿßÿ©‚Ñõ„Åø„Åü„ÅÑ‚Ä∫Íàç·¥óÍàç“ô\\u200c\\u200c’Ω ô·¥Äƒ´≈°„Çπ‚û°‚û°ÔºçÔºç‚ô•‚ò∏Ôºè√Ø‚úø‚ú™‚Äø‚ú™ÔΩ°Ôæâ…†ƒÖÔºõ¬¥‚àÄÔΩÄ„Çû‚ô¨·Éï√≠‚àö‚ãÖ„Çà„ÇäÂ§ö„Åè„ÅÆÊÑõÔΩîÔΩàÔΩÖÔΩíÔΩÖÿ®ÿ±ŸÖŸÜÿ¨ŸÜÿßÿ™∆íœÅ”Ø‚úï‚úï‚úï‚óÑ‚ô´‚ô´‚ï•Ôπè‚ï•‚àÜ¬≤‚Åª√∞√∞¬∞√±√∞¬∫√∞¬∞√§Ã∂ÂÖ•‚ô°ÔººÔø£‚ñΩÔø£Ôºè‚ô°ÔæüÔΩèÔæü≈õƒá‚ñà‚ñÜ‚ñÖ‚ñÉ‚ñÇ‚ñÅÁÇ∫‰Ω†Ëä±ÈñãÊªøÂüéÔºåÁÇ∫‰Ω†ÁáàÊòé‰∏âÂçÉ„ÄÇ√ΩŸÑŸÉÔø¶‚Äæ‚Äæ‚Äæ‚àö‚Äæ‚Äæ‚Äæ‚àö‚ãÖ‚Äæ‚Äæ‚Äæ‚àö‚ùì‚ùî‚ùì‚ùî‚ùì‚ùî‚ùì‚ùî‚ùì‚ùî‚ùî‚ùì‚ñΩ‚òú‚òÄ‚òû‚ú∫‚ú†Ê´ª‚àö‚à†∆®Èõ®ÂÆÆÂ§©ÔΩÅ\\u2061œÄ\\x7f\\x7f\\x7f¬∞‚àöÿ±ŸÇŸÖ„Öé‚ñÑ‚ñÄ‚ñÑ‚ñÄ“õ“õ¬æŒ∑‚úÆ‚ûí‚ò≠—û‚Ä§‚Ä§‚Ä§·ö∫·öæ·õá·õà·õã\\u200b\\u206c\\u206f‚Ä∞„Äû‚ô´‚ô´‚ñ∫‚ô•œâ‚ô•‚ù•‚ù£Õè‚ô™‚ô´‚ô¨ŸÉÿßŸÜ·µõ·µâ·∂∞·µç·µâ·µÉ·∂∞·∂ú·µâ·µé‚ãÖ‚Üí‚àö‚Öõ‚àö‚àöœÜœÜœÜœÜ‚àõ‚àõ·πÉ·ª≥”Ç‚Ç≥‚òºÿ®ÿ≥€åÿßÿ±Âá∫Âè£‚¨á‚¨á‚ë®¬µ‚É£‚É£‚É£‚É£¬ß‚òÜ¬ø‚ÄΩÔΩΩÔæÄÔΩ∞ÔæòÔΩ∞ÔæåÔæûÔæóÔΩ≤ÔæÑÿ≥ÿπŸäÿØÿ©Ôºö¬¥‚û°…≥\\uf0a2√™◊ë◊ï◊ì◊î◊îÃíÃΩÃàÕÑÃàÕõÕëÃçÃ°ÕñÃßÃóÕîÕôÃ§Ãû«íÔºÖŒ¨œÅœÇ‚ñ™‚ñ™‚ñ™ÁΩóËø™Ôºå‰∏πÂ∞ºÊñØÔºåÊù∞ÂÖãÔºåÂáØÁâπÔºåÂ§ß‰ª≤È©¨ÊòØÊúÄÂ•Ω≈≥ ë…õ‚ÜîÁî±‰∫éÊÇ®ÁöÑÂõΩÈôÖ‰ø°Áî®Âç°ÂÖÖÂÄº‰∫§ÊòìÂá∫Áé∞ÂºÇÂ∏∏‚ùï‚ùï‚ùî“ª…Øœç„Åì„Çå„Çè„Ç∏„É•„Éº„Çπ„Åß„Åô„Åã·Éó·Éï·Éò·Éó·Éù·Éú√º≈ü√º·Éö·Éù·Éì·Éò‚à™·ª°Ã°“âÕúÏö∞Î¶¨◊¢◊û◊ß◊ô◊ù“£—ñ‚òø≈ôÎ¨¥Ïä®·¥ò„Åï„Åè„Çâ‚áí‚àû‚ÇÆ»¥«ø»µƒë«ø»µ„Åõ„ÅÑ„Åú„ÅÑÂá∫„Çâ„Åó„ÅÆËÑ≥Ê±Å„ÇíÁµû„ÇäÂá∫„Åô„Åì„Å®„Å≠‚àö‚àö‚àí‚àö¬¥ÔæâÔºõÔæâƒü¬ø¬ø¬ø\\uf0f8”ô‡¶Æ‡ß∞‡¶™‡ß∞‡ßÄÊúâ‚àó√±√∞¬µ√∞¬∞√∞¬Ω√±√±∆í‚àó‚àó‚àó‚àó‚àó¬Æ‚à´Ô∏ÅÂ±±ÂÜÖÊÉ†‰ªã‚ÇÇ‚Üí„Éó‚àíœÄ‚òºœâƒôÔΩû‚àí‚ãÖ‚éõ‚éùÊàëÂÆ∂ÈôÑËøëËøòÊúâÂÆ∂ÂïÜÂ∫óœÇÀÇ‚ôè√•ƒº‚≠ïŒ≥ŒØŒ∂œÖ√æ·∂ú·µÉ·∂∞·µó‚Üí\\u206e◊ê◊ë◊ú‚ô¶‚ô¶‚ô¶‚úø‚úø¬•¬¶…¢≈ç·¥çÃíÕÄÕÅÕûÃΩÕëÃøÃæÕÇÕäÕáÕâÃ¶Ã´Ã≤Ã≠Ã∂‚àö‚àö‚àöŸáÿßÿ™ŸÅÏ†ÄÍ≤É‚ùî‚ùî‚ùî‚ùì‚ùì‚ùì„ÅÇ„Çè„ÅÑÃòÃ≠ÕöÕîÃòÕôÃØ\\uf0d7¬≤‚àöŒ≥…™…ö…´…©…™…®…´…¨…™…ö…ß…ü…ß…¢…π≈æ≈£√∏≈ßœÜ‚àí≈ô√æ‚Ç•«ª·É°·Éû·Éö·Éò·É°◊ë◊ê◊ï◊ï◊ô◊®Àâ‚ùï‚ùï‚ùïœáœÅŒ≠œÇ·¥ø„Ñò„ÇÖ‚àú‡≤•‡≤•‚ô•—ê·¥è·¥Ñ∆¥„Ç∏„É•„Éº„Çπ„Çè„Åì„Çå„Åß„Åô„ÅãÔΩñÔºãÔΩà‚ÇÇÔΩìÔΩè‚ÇÑ‚ñÜ π…©…®…ß…¢…¶…ö…¨…∂‚Ñ∞ ø¬ø¬ø‚ùû‚óè‚óèÂæ©Ê¥ªÁæé‚àí¬∞‚Å∞‚àí‚ãÖ‚ãÖ‚ãÖ‚ãÖ‚àí‚Üì‚Üì‚ûï∆≠ ú·¥á‚àß¬¨‚àÖ·¥õ·¥á·¥ç‚óï‚Äø‚óïÕ©ÕÇÃæÕ™ÃÄÃãÃòÕàÃ∫Ã™Œ¨Œ≥Âè≥Áîü„ÅçÁâ©„ÅÆÊÑõ·Éê·Éõ·Éù·Éï·ÉÆ·É°·Éú·Éê‚óÑÕ°¬∞¬≤‚â• ú¬¢¬∂‚àÜ‚àÜ¬¢¬∂¬¢¬∂¬∂¬∂‚ë°‚à´‚àöÕ°¬∞·¥•ÿ¥ÿßÿ°ÿπŸÑŸâ‚è∞‚ô•‚Äø‚ô•ÔΩèÔΩé‚ñëƒ±‚úøƒõ¬∂‚îÅ◊î◊ï◊û◊ï◊ê◊ô◊ùÂèãÁêÜËúÇÊ±üË©±‚ô°‚ô°‚ô°‚úï‚úï‚úï‚úïÀ£‚Öì¬≤‹î‹¢‹ú‹îÕ°‡ºé‡∫∂‹ì·¥Ä·¥Ö·¥á ü·¥á‚Éó‚ÇÑ“ó”©„Éú„É´„ÉàÁîüÊ¥ª¬°¬°‡Æí·É°·Éò·Éß·Éï·Éê·É†·É£·Éö·Éò·ÉóÔ∑∫\\u202e‚ë†¬≥Ôø£„Å•…™‚àâ ä…ô‚úø‚Äø‚úø√¢ÔºçÔºçÔºç„ÉÜ„Éñ„É´‚úº‡≤•·ó£‡≤•¬∏‚ÇÖÃ≤ÕàÃ¨Ã≤‚Ä§‚óï·¥•‚óï—ñ—ñ—ñÿØÿßÿ±ŸÖ‚§µ‚â§„èí‚ÇÄ‚ÇÉ√∞¬≤√±√∞¬µ√∞¬º√±\\x8f·Éê·Éú·Éí·Éî·Éö·Éù·Éñ·Éî·Éë·Éù‚Ü£œïœÅŒ≥Œ∂œåœÇŸÇŸêÿ±ŸíŸÇŸê€åÿ≤ŸíÿπŸÑ€å‚úò≈≥Íùë‚àí¬±‚àö‚¥ò‚áí‚ÇÑ‚Üí◊î◊ï◊ì◊¢‚ùî‚¨á‚¨á‡Æö‡Æ£‡Øç‡Æü‡ØàÍï•‚ä±‚ïÆ„Éí„Éº„ÉìÔºüŸà‚¶Å‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‚¨á‡Æ™‡Æ©‡Æø‡Æ™‡Øç‡Æ™‡Æ®‡Øç‡Æ§‡ØÅ‡Æö‡Øç‚ùï‚ùï‚ùï‚ùî‚ùì‚ùì‚ùìŒ∂√∞¬¥√±√±∆í√∞¬≥√±∆í√±≈æ„Éà‚û™‚ô†‚ô†¬∞Ôºù¬Ω‚Äæ‚àö¬∞‚àíƒ°“â≈Ø“âƒã“âƒã“â√Ø“âÔºûÔºû≈ó µ≈≠ ∏≈´ ∏ƒ© ±≈∫ ∏≈≠ ≥≈µ µ≈∑ ∏≈æ ∏≈∑ ±≈º ∏≈± ≥ƒ£ µ≈≥ ∏≈≠ ∏ƒ© ±≈æ ∏≈µ ≥≈´ µ≈∑ ∏ƒß ∏≈∫ ±≈´ ∏≈≥ ≥≈© µ≈± ∏≈´ ∏ƒ© ±≈≥ ∏≈ø ≥ƒ£ µ≈∑ ∏≈µ ∏ƒ© ±ƒ∏ ∏ƒ∫ ≥‚òõ‚òõ◊™Õú ñ·õè·õñ·õö·õü·ö∑·õÅ·õãŒ∏„ÄÅ‚àã¬™√±\\x8d√±√∞¬æ√±¬®‚Å¥‚àö‡•êÕçÃ£ÊÇ®ÂøµÂì™‰∏ÄÊâÄÂ∞èÂ≠∏ÔºüŸÅŸáŸÖ·¥π‰∫ëË£≥ÁæΩË°£¬≥‚àö‚ú®‚ú®‚ú®\\x98√†√†√†√†√†√†√†√†‚àö¬≤‚Ç∏‚ôè„Å§ÔΩã≈º‚ñ´‚ñ´‚ùî¬£◊í◊¢◊í◊†◊ò·ö®·ö¢·õÉ·ö®‚ùÅ‚ùÅ‚ùÅÔºüÔºü‚ùï‚ùîÔºúÃÖ‚à©‚à•ƒ∫ÿßŸÑŸÖÿ∫ÿ±ÿ®\\u200eÈªëÈæôÊ±ü\\uf0d3\\uf059‡ß≥œÖ‚àÇÿßŸÑŸÜŸáÿßŸäÿ©≈üƒ±¬©‚äÑ√ß“ø‚úó„Å©„ÅÜ‚àö¬≤‚àö‚ôä·Ö†·Ö†·Ö†·Ö†·Ö†·Ö†·Ö†·Ö†·Ö†·Ö†‚ò¢‚à¨‚àû‚àû√≤√≤‚Üì„Å£ÀòÃ©‚ï≠‚ïÆÀòÃ©„Å£√∫‘â‘â√∫«øÃ∑Ã∑‚àò‚Ä≤‚Ä≤‚Ä≤Œá◊õ◊û◊ï—ì—ìË±°ÂΩ¢ÊñáÂ≠ó‚ïëÿ¥ŸÖÿßÔΩâÔΩì·¥úÔΩïÔºÉ‡Æê√¢√†√∏√†Ã¢Ã¢Õ†‚ñÖ√Ø√Æ√§√´√®√≠√≠√Æ√©◊ï◊ô◊ï◊ô◊ï√•≈≠„ÄñÔπù‚àû‚àû‚àí‚àí‚àíÃÑÕ•ÕåÕíÕÇÃ°ÃØŸàŸÇÿπ‚ï∞‚éØ‚óÑ‚ñ∫«ù…î·¥Ä‚ñí„ÄñÈ≠öÊãì‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡Ø∏‚úø·∏•„Éë„Çπ„ÅØÊúîÈñìÈõ∂„ÅÆÂêçÂâç„Çç„Åæ„ÅòÔºãË™ïÁîüÊó•Êó•ÔºèÊúà„Åß„Åô„ÄÇÔ∏µ‚ÄøÔ∏µ¬¥ÃÖÃÑÃëÕÅÕÖÕÖÃùÃ©‚Å¥‚Å¥¬≥…™≈ã‚ÅÇ‚Öπ◊û◊ì◊ô‚ùï‚ùï‚ùï‚ùî‚ùî‚ùî‚ùì‚ùì‚ùì‚¨á¬≤¬≤¬≥¬≤ ï·¥• îÈ£ü‰∫ã„Åô„Çãœâ¬∞ÕÜÃΩÃöÃáÕÜÃïÃÑÃáÕêÃΩÕÖÃ®ÕöÃ®ÃôÃ†Ã©Ã®Ã∑ƒç√´·É©·Éî·Éõ·ÉùÊàëÂÆ∂ÂêéÈù¢Êúâ‰∏ÄÂÆ∂ÂïÜÂ∫ó‚óè¬¥œâÔΩÄ‚óè—ï—ï≈≠ÔΩöÔΩàÔΩÖ‚Öπ‚Öπ‚Ö∞Â∑¶ÀäÀäƒèƒèƒìƒ°≈≥‚ñ≥\\u206c\\uf0e8Œª‚ûñ‚ûñ ü ∏·µí·µò‚ïü‚ïù‚ï¨·Ö†·Ö†·Ö†·Ö†·Ö†‡ºöÕìÃñ‚Ö∞‚Öπ‚Öπ‚Ö±ÿßŸÑŸÖÿ¨ÿØ‚ûè‚òõ„É©„É™„É´„É¨„É≠·¥Ö‚ùî‚ùï‚û°‚û°ÂØù„Åæ„Åô‚ñÉ·õà·õñ·õü·õöƒ∑ƒ∑◊î◊®◊ô◊ùœÄŒªœÖ‚ñ≤Œ≠œáœÇ‚ñê‚ÑÉ·ä†·ã≠·âÄ·à≠·àù·É¶Œ≥œÄœâ‚àû‹ì‹®·É°·É°·Éô·Éë·Éö‡≤†Áõä‡≤†·Éö·¥ò…™…¥·¥ã·Éû·Éê·É¢·Éê·É†·Éê”ëœÄœÄ¬∑¬º¬≤¬≤¬≤¬≤¬≤‚ÅâŒªŒæŒØœÖ‡¶ö‡¶æ‡¶á‚ùÑ‚õÑ‚ñº‚àí‚àö√∞¬ø√∞¬æ√∞¬¥√±√∞¬∞√∞¬∑√∞¬¥√∞¬µ√∞√∞¬µ√∞¬Ω√∞¬∏√∞¬µ…ô‚ÇÇ‰∏ñÁïå‰∏äÊúÄÂ§ßÁöÑÂüéÂ∏ÇÊòØ‰ªÄÈ∫ºÔºü“ì“±‚û§‚å£‚Üë‚Üë µƒ• ∏≈≥ ∏≈≠ ±≈≥ ∏√£ÃÆÔπ£‚ÑÉ“±‚àö√∑„Åå‚à©‚à©‚Ä≤‚ùî‚ùï‚Öî\\u202a\\u202a·¥ä·¥ú‚óãÔΩìÔΩîÔΩèÔΩíÔΩç‚îÇ‚âß‚ó°‚â¶Â∑¶ËæπÊòØÂÅúËΩ¶Âú∫„Ö§„Ö§‚ñà‚ñà‚ñàƒÖ“ó·¥Ä·¥Ö·¥ç…™…¥…™…ì«ù·õã·õã‚û≥·¥ã√∂√∂‚Åø‚Å∫¬πÈ£ü„Åπ„Çã‚àöœÄ√™√∞√Ø√ª·Ö†‚á±ÔΩìÔΩÅÔΩÑÔΩÇÔΩèÔΩôÔΩì‚Çô‚Çí‚Çú‚Çï·µ¢‚Çô‚àí‚Üí‚àíÕõ·¥Ñ ü…™·¥òÍú±·¥áÃ•Ã≤Ã¶ÃÆÃØ„èí‚ÇÄ‚ÇÉÿßŸÑŸÖŸàŸÇÿπ¬≤‚â§·¥∂‡∏ø√¶‚ÇÅ‚ÇÅ‚Ç™ÔΩîÔΩàÔΩâÔΩìÏûòÌïòÍ≥†«é‚úà‚àí‚àó‚àíÕØÕÆÃáÃëÕóÕÜÃÜÃÆÃÆÃóÃüÕñÕàÃò·Äë„Ç¢„Éâ„Éê„Ç§„ÇπÂ§âÊÖã‚Äï\\u200b„Å©„ÅÜ„Åû„Çà„Çç„Åó„Åè„ÄÅ„Åì„Å°„Çâ„Åì„Åù„ÄÅ„Åì„Å°„Çâ„Åì„Åù„Å©„ÅÜ„Åû„Çà„Çç„Åó„ÅèÔºü‚Å∑√°ŸÑŸäŸÑÿ©—ú≈≥“°·ª£‚òºÃãÃãÃçÕ≠Õ≠Õ£ÃÉÕôÃôÃòÃ© ú·¥á ü·¥òÔΩà ÅÕëÃÇÕ¨ÃßÃ≠Ã£Ã§ÕáÃû‚ãÖ‚Å¥‚úì‚åò—ñ“£—ñ√™√Æ√Ø√®√ø·É≠·Éî·É®·Éõ·Éê·É†·Éò·É¢·Éî·Éë·Éê‰Ω†‰ª¨‰∏ÄÂçÉÂ§öÂàÜÂíãÁÇπÁöÑ‚úñ‚àÇ‚ùß‚ùÉ¬∞‚Ä≤◊ô◊ô◊ü◊õ◊ô◊ô◊ü‚ÇÉ‚ôéÔºã‚ÑÉ¬≤‚Åµ\\u200c¬¥ÔΩ•œâÔΩ•ÔΩÄÂèôËø∞‰∏Ä‰∏™ÊñáÂåñËØØËß£ÁöÑ‰∫≤Ë∫´ÁªèÂéÜÔºåËÆ∫Ëø∞ÈóÆÈ¢òÊâÄÂú®ÔºåÂπ∂ÊèêÂá∫Ëß£ÂÜ≥ÈóÆÈ¢òÔºåÊîπÂñÑÂ±ÄÈù¢ÁöÑÊñπÊ°à‚ï∞·Éì‚úø·Éì‚ïØ‚ô™‚ô™·Éì·Éì·ÉîŒÑ‚àßÔººÔø£‚ñΩÔø£Ôºè≈ì≈ì‚àí‚àí‚àö≈Ñ‚àö‚àö‚àö‚àö·¥ã·¥è…¥·¥õœÅ“õÔΩôÔΩÅÔΩìÔΩïÔΩíÔΩÅÔΩèÔΩãÔΩÅ\\uf0f7‚ùÄÀö¬≤„Åæ„Çä„Å™„Åï„Çì‚ùå‚ùå‚ùå„Äå·¥ú…™·¥Ñ…™·¥Ö·¥á ô·¥è è—òÏ†ÄÎäî◊ë◊®◊ô◊ê◊úœÄ√∑«´‰∏≠ÂõΩÂ∞èÂêÉÕ°·µî∆®œÅ‚ùû‚àö‚â§‡¶Æ‡¶≤‡ß∞‚ï∞·Éì“ì ö«ù‚ÄΩÔΩÖÔΩÇÔΩèÔΩìÔΩàÔΩâÔΩî‚àö‚àö·Éõ·Éî·É£·É¶·Éö·Éî·Éï\\uf044…™·¥çÃÖÕ®‚éõ‚Åπ„ÇÄ„Åã„Å§„Åè¬ø¬ø¬°¬°¬°‚òë√∞¬æ√∞¬±√∞¬µ√±√∞¬µ√∞¬∂√∞¬Ω√∞¬æÈáå‰Ω≥‚ùì—öÔΩÇÔΩåÔΩÅÔΩÉÔΩãÔΩ°Ô∏øÃÄÔΩ°·µó ∞·∂¶·∂∞·µè·∂¶·∂∞·µçË°å„ÇíÂÖ±„Å´„Åô„ÇãÃÇÃÖÕÑÃçÕÑÕãÃèÃíÃõÃÇÃöÃáÃáÃΩÃøÃàÃÄÕÄÃÉÕÉÕäÃÜÕóÃÜÃΩÃÇÃçÃãÃäÃáÃàÕöÕÖÃ®Ã∞ÕöÃúÃ¶ÃÆÃúÃ®Ã¶ÃóÕìÃ≠Ã∞Ã™ÃòÃ®Ã§ÕéÃñÕàÃ∫Ã∫ÕôÃûÃ∞Ã≠ÃªÃúÃ•Ãº“õ—ñ√∏‚â°·¥∏Õ°‚óâ\\uf0d0‚ûú¬∫¬∑‚úÖ‚ÑÖ¬©√ª√®¬∫Âä©Êµ¥ŸÄŸáŸÄ·¥Ñ·¥è·¥õ·¥ò‚àö‚àö‚àö‚àö‚àö‚àöÔΩÖ¬≥¬≤¬∞¬∞¬∞ÕÇÃêÃáÕÆÃèÃîÃÄÃöÃ•ÃùÕÖÃÆÕôÕàÁßÅ„ÅØ„ÅäÂ∞ª„ÅÆ„É©„ÉÉ„Éë„Éº„ÇíÊåÅ„Å£„Å¶„ÅÑ„Åæ„ÅôÂçêÿ£ÔΩ∑ÔæèÔæÄÔæòÔæõ\\u2061\\u206f\\u200b∆í‚ñà‚ñà‚ñà‚ñí‚Çò‚Çë‚àö‚àí‚©æ√§√§‚ô°‚ô°„ÅØ„ÄÅ„Åå·¥∫ º‚ôãÂâçÃñÃ™Ã•ÕÖ‚Å¥¬≥¬≤‚≠êÎöúÎëêÎöúÎëê‚ô°‚ô°‚ô°‚ô°‚ô°‚ô°‚ô°√¥‚à†‚à†‚ò†„Çè„Å£„Åó„ÇÉ\\uf0f6„ÄíÃéÕ§ÃΩÃçÕäÕ≠Õ°ÕáÃôÕÖÃØÃºÕöÃ†Ôºã‚àö‚ô©Â∑ùÊú¨ÂÖàÁîü„ÅÆ„ÇØ„É©„Çπ„ÅØ„ÅÇ„ÅïÊó©„ÅÑ„Åß„Åô„Åã·õÉ·ö¢·ö±·õÅ·õÉÏì∞Îã§‚à°◊ê◊ï◊ï◊ô◊®„Äå‰∫úÈÇ™„ÄÖ„Äç„ÇíÂπ≥‰ªÆÂêç„Åß„ÅäÈ°ò„ÅÑ„Åó„Åæ„Åô„ÄÇ\\uf0e6Ïù¥Í≤É„Äóÿåÿ™ÿ∑ŸÑÿπÿ™‚¨á‚¨á‚¨á‚ô¶ÕÉÕÜÕùÕêÃëÃûÕöÃØÿ¥ÿπÿ±·É®·Éï·Éò·Éö·Éî·Éë·Éò‚ñº‚ñº—ôƒì„Äó„ÄñÔºÜ‚ÇÅ‚Äû‚ô•‚ô•‚ô•„Éï„É¨„Éá„É™„ÉÉ„ÇØÃöÕÅÃΩÕûÃõÕÜÕ°ÃèÕÜÃûÕáÃ™ÃπÃôÕàÕú√¥√ª√¢·ö®·ö¢·õÉÃÜ“°‚Üì‚Üì‚Üì‚ò£≈æŒ¥‚Ç¶√∏≈æŒ¥‚ò£√±√∞¬∞ÔΩèÕ¢ÕÖÃÆ—•Íµ¨Í≤Ω‡∏∑‚ñø‚Åª‚Å¥¬π¬≤¬≥‚Å¥‚Åµ‚à£‚Üí„Äë\\uf061Ô∏∞ƒ±ƒü‚ó¶‚Äº‚ÄºÍî™‚àòÃóÃºÃ§Ã†Ã∫ÁæéÂ§ú—ñ“õ“±„É†Â∞∫‚à™„Å°Âåï„Çå„Ñö“£“õ“±‚Å¥¬≥‡Æá‚à´ÃπÃ£„ÖÅÕè”ó‡∏áÔºã„Öõ…¥‚õà„Åä„ÅÜ—£\\u200b\\u200b\\u200b√∑√∑√∑Ôºæ„Åµ„Å´„ÇÉ„Åµ„Å´„ÇÉ·¥æÕì‚óè‚óè‚óè‚óè‚óè‚óè‚óè‚óè\\u200b\\u200b\\u206a·¥á·¥¢·¥Ä·¥òÍ∞àÍªòÏöîÎßûÌåîÌï¥Ïöî‚ô•‚ô•‚©Ω‚ôå è·É´·Éï·Éò·É†·É§·Éê·É°·Éù—ù√∏·ãô◊ó◊ï◊©◊ö·Éì·Éê·Éõ·Éî·ÉÆ·Éõ·Éê·É†·Éî·ÉóÂØù„Çã◊ê◊ô◊üÏñ¥Îñ§≈ü‚ÇÇ‚ÇÅƒ°·π≠·π≠ƒÅœÄ‚âà‚ùù„ÖÖ√∞¬¥√±√±∆í√∞¬≥√∞¬æ√∞¬µ‚âà«£‚Ç±Œ∫√±Œ¥‚ûñ‚ûñ‚ûñ„Ç§‚òπ—ô¬Æ¬∞‚©Ω‚©Ω¬∞Õ®ÃΩÃÑÃ™Ã©ÃúÃúÃôÃúÃÆÕô¬°ÔΩÇÔΩèÔΩöÔΩàÔΩÖ\\u2062‚ä•ÕåÕõÕåÃáÃáÃçÃòÃ´ÕàÃ≠ÿßŸÑÿπŸäÿ¥≈õ\\u200e·É°·É°·Éò·Éû·Éô·Éî·É†·Éò·Éê·É°\\uf072‚úì·¥ç·¥Ä—£ÔºùÔºûÔºû√ø\\uf0b0„Éí„É≥„ÉàÔºöÊó•Êú¨Ë™û„ÅÆ„Çµ„Ç§„É≥Ôºã‚ÑÉÔºüÿßÿ≠ÿ∞ŸÅÕöÕé‚îÜÔΩâÔΩéÔΩîÔΩÖÔΩíÔΩÖÔΩìÔΩîÔΩâÔΩéÔΩá‚àõ√∂√ü„Å™„Çì„Åß„Åì„ÅìÊú∫ÔΩö‚Ä≤√ª‚ÇÉ‚ÇÇ“ù·ãô‚Ñ¥‡§ó“ù¬™‚ç∞ÕíÕüÃ®Õï‚ãØ‚å†«ù«ù¬°·Éí·Éî·É¶·Éú·Éò·Éî·É†·Éò„Å°„Çá„Å£„Å®ÂæÖ„Å£„Å¶„ÇÇ„Çâ„Å£„Å¶„ÅÑ„ÅÑ„Åß„Åô„ÅãÔºü‚ñ∂‚ñ∂ÔΩãÂè£ÂåïÕ≠ÕÇÃíÕ®ÃûÿßŸÑŸÑŸáƒï‚ñ™‚Ç¥‚àö‚ãÖ‚àí‚àö\\uf0e7\\uf0b7‚ñèÕ¨ÃÜÃëÃÜÕÉÕßÕ¢Õ°ÕñÕáÃóÕô¬∑¬≤¬∫‚Ñ¢‚ô£‚ô£‚ô£ƒá”ß“ùÂçÇÂ∞∫‰πáÁà™‰πáÁà™‰πá‰∏Ç‡∞é·µÅ·¥¨ÔºåÕ•Õ≠ÕÜÕÜÃÖÕ¨ÕØÃêÃµ“âÕïÕñÃüÃóÃ≥Ã•Ã≤ƒ∑„Öó‚â§‚àöœÄ‚àí„ÖÇÔΩÜÔΩèÔΩéÔΩîŸáŸÜÿß‚à∂¬π¬≤”ô“£œáŒØœÅœÇÂ∫≠…ûœÇ…õ\\uf0b4‚ÇÅ‚ÇÖ◊ê◊ì◊†◊ô◊ê◊úÕ¢Õ°¬∑‚Åª¬≥¬π‚àí‚ãÖ‚àí‚à¢¬∞‚àó‚àó‚àó‚àó‚ùì‚ùìÔπû“ô“ôÔΩÉÔΩèÔΩïÔΩåÔΩÑ‚ùï‚ùî‚¨á‚¨áÔΩé¬µ—í‚ô†‚ô£‚ô•‚ô¶‚Ä†Œ¨œÄœÅ„Ç∑‚úèÁÇ∫‰ªÄÈ∫º‰∏≠Âúã‰∫∫ÊîæÁÅ´ÁáíË•ø‰ºØÂà©‰∫ûÁöÑÊ£ÆÊûóÔºüŒØ◊õ◊ô◊ô◊ü¬≤¬∞‚õì‚ìöŒæœÅœÅÕ¨ÕëÕèÃ°ÃïÕçÃ¶¬£¬£Ãà√≠√•„Öìƒ±ƒüƒ±‚ô†‚ô†‚û¶·µÄ·¥°¬ºÂπ≥ÊñπÂÖ¨Èáå„ÄÇ‚ò£„ÇÜ„ÅÑ„ÇíÂàÜ„Åã„Å£„Å¶„Çã„Éé„ÅåÈÅ∏„Çì„Åß„Åè„Çå„Åü„Éó„É¨„Çº„É≥„Éà„ÄÅ‰ªäÊó•„Ç§„ÉÅÊúüÂæÖ„Åó„Å°„ÇÉ„ÅÜ„Åã„ÇÇ‚Å¥¬≤Áúã‚ö§‚òÇ‚úø‚ä±‚ïÆ‚ô•‚ô•‚ô•‚ô£‚ô£‚ô£À¢·µó·µí·µñ¬≤¬π”éÊò†Áîª„Äé„Ç≥„Ç§„É≥„É≠„ÉÉ„Ç´„Éº„ÅÆÂ•≥„Äè‰∫àÂëäÁ∑®Êú™‰ΩìÈ®ì„Çæ„Éº„É≥„ÅÆÊò†Áîª„Åü„Å°ÂõûÂæ©Êñ∞„Åó„ÅÑ„ÉÅ„É£„É≥„Çπ—ì«ù‰∏´‰∫∫‰ª®‰∏Ö‰ªà‰ªé‚å°œÄ‚ÄπŒªŒ¨œâ‚Çâ√†‚ö°‚ö°‚ö°·É•·Éï·Éò·É°ƒ±≈üƒ±‚à£‚à£‚Üí√ß√∂‚úùÕ•ÃΩÕ≠Ã™Õö‚Öπ‚Öπ«êÿßŸÑŸÅÿ∂ŸÑÁ∫ßÔºåœÅŒ∫·¥õ·¥áœàÃá÷èÂÖà◊ê◊öÃÖÃáÃëÃêÕùÃùÕïÕÖ√≤Ôº†ÔºæÔºçÔºæ·¥äŸáŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅŸÅ‚ÅøÀà‚ñ°ÔºåÔºåÕÖÃºÃòÃ©—ò¬Æ¬Æ—û¬Æ¬¨ƒ©≈Ç‚â§‚â§‚â†‚ÜíÊÑõÿßŸÑŸÜÿ≠ÿßÿ≥ÿπ‚àó‚àí‚àó‚àó‚àí‚àó‚ô´„Çè·õñ‚ÇÜ‚òü‚òú‚òπ‚òπ‚öê·ª£¬±‚ùñœÜœâœå·¥õ Ä·¥Ä·¥õ·¥è Ä·µ¢‚Çú‚Çï‚Çí·µ§‚Çú‚â†‚ãáŸÅŸäÏïÑÏ£º ï‚óâ·¥•‚óâ î◊¢◊û◊ï◊ß◊ô◊ù√æ≈´‚Å∫„Äñ‚åò„Äó‚òü‚àö¬≤¬≤√∑”ô“óÂêçÂâçüí©¬Ω‚Öì¬ºÕü◊õ◊ú‡Æé‡Æ≤‡Øç‡ÆÉ‡Æ™‡Øç·¥¥Œ≥ŒØ‚à£‚à£ÔΩÇÔΩÖ‰Ω†Â•Ω‰Ω†ÊÄé‰πàÊ†∑ÔºåÂ§ßÂÆ∂ÈÉΩ‰ΩøÁî®Ë∞∑Ê≠åÁøªËØë‡Æ™‡ØÜ‡Æ£‡Øç‚ñ∫¬≥œáŒæœÇ‚Äº‚Äº‚Äº‚Äº‚îÄ‚ùì‚ùì‚ùì·ö∑·õÅ·õí·ö¢‚ôõ‚Ç≠“è≈Ñƒâ≈•«ª”Ü‚ôõŸÑŸàŸÜÍπÄÍ∞ïÏ≤†ƒãÃìÕ°ÕÉÃÜÕåÃéÃêÃ≥ÕéÃ±ÕüÃ±Õ¢ÃπÃñÃ¨ÿ•ŸÜ◊ó◊ï◊®◊£Ã´ÕâÃÆ¬•¬£‚¨Ö‚¨Ö‚¨Öÿ∞ÿßÿ™‚à†‚àòŸàÿ£ÿµÿ∫ÿ™·Éû·Éô·Éï·Éì·Éê·Éï·Éî·Éë·Éê·É®·Éò·Éê‡¶Ü‡¶Æ‡¶ø‚úø‚Ç™ƒëÔøºÔøº‚úú‚úú‚úú„Å∏€û”≠ÃãÕ£ÕõÃâ“Ø‰∏Ç·µï·µÉ·µá·µí·µò·µó„ÅÆÔºüÔºüÔºü„Å•Ôø£¬§‚òÜ√µ√¶ÿ≠ÿßŸÑŸÉÔΩîÃòÕà¬≥¬π‚Å¥…ëÀê„Ç¢„Éã„É°„Éä„É´„Éà„Çµ„É¢„ÉÉ„ÇØ„É©„ÉÉ„Çª„É≥„Å®„Éô„É´„Çª„É´„ÇØ„ÇÇ·É†·Éù·Éí·Éù·É†ÿßÿ≥ÿ™ÿ∑Ÿäÿπ‚ùß‚ùß‚ùß‰∫º‰∏π‰πÉ‰∏πËÆ¢Êà∂Âúü‚úö‡∞ûÕÖÕöÃùÃ§Ã¶¬Ω‚àö‚à®‚ùÑ‚àó‚àó√∑‚àí‚Üí‚àí‚àíÎÑàÎ¨¥ŒªŒªŒ∑Œ∫Œ¨ ô‚òØ‚òØ‚òØ¬∂‚ñì‚îº√Æ◊ê◊†◊í◊ú◊ô◊ï◊™√±√°√Æ√∞√™√† ç“ø‚õ∞\\uf0ae√∫ÔΩáÔΩÇÔΩÅ„ÄÇ√µ‚Öù·¥±‚Öî¬≤≈´Êú¨ÂΩì„Å´“Ç\\x90Õú ñ‡≤∞‡≥É—õ‚Å∏‚àí‚Ü´‚Ü¨‚Åπ‚Å∞“ª‚úØ‚úØ‚úØ\\u202a\\u202a\\u202a\\u202a\\u202a\\u202a¬∫“∑‚Ä≤«ù…î öÔπï‚ú®·∂Ñ‡∏ô‡§ó‚ô°‚òÜ‚ñà„ÄêÊñ∞ÂìàÂ∞îÊª®ÂõΩÈôÖ„ÄëÂ∑≤Âá∫Âè£Áõ¥Â∞Å¬∞¬∞ŒªŒØ·¥Ñ„ÄóœÄŒæŒ∑—ñ—û◊¶◊ú◊ô◊ú¬≤¬≥œÜŒØÿ≥ŸàŸâ„ÅØ‚ñáŒªŒ∑‚ô™ Ä‚Öì\\u200b\\u206a\\u206d·∫°‚á∂‚ôø\\u200b\\u206b\\u200f„Å´‚Åª¬π„Å©„ÅÜ„ÇÑ„Å£„Å¶‚ùåÔºú‚àö„Éö„Éã„ÇπœÄ‚àö‚àö‚àö‚àö‚àö‚ãØÃÖ‚à∞√†√°√¢√ÆŒ¥Œ∂Œ∫√π‚àí‚àí‚ãÖÔΩ°‚à©√∂√§·É®·Éï·Éò·Éö·Éî·Éë·Éù„ÄùœÄœÅœåœÅÃ≠ÃùÃºÃ≥ÕàÃÆÃ¢Õ†Õ°‚à£‚ÇÄ‡≤†„Å†„ÅÑ\\uf02dœÄ¬≤¬ø¬ø¬ø¬øÃ∑√∞√±‚Äπ√∞¬±√∞¬µ√±√∞¬∏√±√∞¬µ√ßƒ±ŸÖÿ™ÿÆÿµÿµŸäŸÜ‚Ü©√ß„Äê„Äë≈≥≈£“ç·É™‚Ñ≠‰∏ÄÊú¨‰∏ÄÊú¨‚ù£◊°◊§◊®◊ôÊó•Êú¨Ë™û‚úΩ‚úΩ‚úΩ‰Ω†Áâõ‰ªÄÈ∫ºÁâõÏù¥‚ô™‚ô´“ª”ô·¥Ñ·¥è·¥ç‡≤†‡≤†‚ï±\\uf02d\\uf02d‚Ñì◊ô◊î÷º—Ø…ê„Å≤„ÇÅ‚õÑ‚Üí‚àû‚ò∏‚ô•„Çí„Åô„ÇãÊó•Êú¨Ë™ûËÉΩÂäõË©¶È®ì‚áÑ…õ…µ‚è≥‚àö—ñÔºù¬£¬£‚Ç©¬Ω‚àà‚àí‚ò¢·πß‚ÇÆ‚±•ƒº—ú‚Ñ∞‚Ñü‚ò¢‚à®¬¨‚Å∏‚àí‚àö‚àíœÖœåÈúßÂàá‚Ñí‚Ñ∞‚ÑúÍ≠ø‚é†‚éû‚ô°‚Äø◊ú◊î◊†◊ò◊ê◊ô„Äñ„Äó…ô ä¬π‚Å¥¬π‚Å¥¬≥‚Å¥ÊºÜÈªí„Å´Ë∫ç„ÇãÂºßÊøÅË¶áÁéãÁØÄ‚Ä∫‚àö‚àí‚Äê‚úø‚úø‚ä±‚ïÆ‚Çí·µ§·µ£‚Çë√π√¨√º√ü·ãò·àò·äïŸçÕàœÄœÖÔºúÔºú„É©‚Ñã\\u2061‚à†‚ùï‚ùî‚ú¥‡¥Ø‚àí‚àí√üœÅŒ¨Œ¥ÔΩìÔΩèÔΩçÔΩÖÔΩîÔΩàÔΩâÔΩéÔΩá‚õë·¥°·¥Ä…¥·¥õ¬ø¬ø‚ùî·µâ‚ñ∂ Ä·¥á‚ÜëÔΩíÔΩáÔΩÇ‚è¨‚ö°‚ãÖ‚àíÔø•œÄ‚àö·Ö†·Ö†·Ö†·Ö†·Ö†·Ö†·Ö†ÿ±ÿßÔºÖÔºüÔΩÑÔΩíÔΩïÔΩáÔΩìÔΩìÂèòÊÄÅŒªœÖŒ∫œåÔΩãÔΩÅÔΩãÕåÃÉÕ®ÕäÕ¢Ã©Ãñ‚àö\\u200e»ùƒØ≈ß»µ‚ã®‚ùÉ‚ã©Õ¢Õû“âÕû◊°÷∏◊í◊ï÷π◊ú‚òÄÃ≠ÃùÃ∞ÃØÃùÃüÃ†¬≤Ôºù‚ùï√§√∂√º·¥õ ú…™·¥ò·¥á·¥º‚àõ‚àö‚ôï‚òº‚òº‚òºŸáŸÄƒõ≈ô‚àí‚ÜíÃµÃ∏Õü“â‚úø‚óÑ‚ïó…¶…±‚ï®\\u200b\\u206c\\u206f\\u206eÊÑõÊÉÖ‚ï≠·ÉìÂú®ÊàëÂÆ∂ÁöÑÂè≥ËæπÊòØ‰∏Ä‰∏™ÂÖ¨Âõ≠„ÄÇ√∂ÃéÃ¨Ã≠ÃôÃ≤Ã¨¬Æ¬©‡∞•‡∞•·Éî·Éö·Éò·Éô·Éù·¥Æ·¥†¬¥‚à©ÔΩ°¬¥œâ‚õΩ‚úªÂÖ•Âè£…≥·ª£ ëÂú®Œ∫œÅŒ≠œÇŸÉŸäŸÅ√ø√¢√´√ø√•√≤√±√ø‚Üê\\u200f◊©÷∑◊Å◊ë÷∏÷º◊™\\u200f\\u200e“´“ó”ô√•\\u200f◊ô◊ô◊ì◊ô◊©◊¢‚û¶‚ô†‚ô†ÔΩÇÔΩÅÔΩíÔΩèÔΩé√ß…ôÿπŸäŸàŸÜ·Éõ·Éê·Éú·Éì·Éê·É¢·É£·É†·Éò·É°‚Ñ¥‚ÇàŒ¨Œ∑œëœÅŒ≠Œ∞Ô∏µ‚ÄøÔ∏µ‚ñ∫‚ñ∫‚ñ∫‚Åª¬≤ÿπÿ∑ÿ±ŸäŸÖÿß‚Üê‚Üí≈üŒæÿ¢ÿ∞ÿßŸÜÔæü‚ñΩÔæüÿ•ŸÑŸäŸÉ‰πÉÂ•áÂ•áÕ©Õ™Õ°Ã¶ÕôÃπÃ©ÃóÃ´«ª√∞√¶√æ„ÄçÃ≤ƒ±‚àÇƒ±‚àÉ‚óÇ‚ñ∏√∞√±∆í√∞¬¥√±≈ì·Éê·Éõ·Éù·ÉÆ·É°·Éú·Éê¬ø\\x81·µÉ·µê·¥õ·¥è\\u202d\\u202cÈÄôÊòØÂåó‰∫¨„ÄÇÈù¢Á©çƒ≠ é·Éì·Éê·É¨·Éî·É°·Éî·Éë·É£·Éö·Éî·Éë·Éò·É°¬π√∞¬∏√∞√∞¬∏Â∑ª„ÅçÂØøÂè∏—≥‚ôå‚ôç◊õ◊ú◊†◊ï¬ß¬ß√¶√¶‚Äë‚ÇÅ‚Çá„èí√©—©≈Ø‚àí‚Äæ‚àö»≥‚Ñå‚Ñ≠‡ßÅ‡¶≤‡¶∏„Åø„Çì„Å™„ÅÆÊó•Êú¨Ë™û◊¢÷∏◊í◊ï÷π◊ú‚óè‚óè‚óè‚ÄíÔΩá\\uf03dÍ∑∏Í≤É‚ù¢“ù≈£‚¥ò√•—ü‚òØ¬∞¬ø‚ô†‚ô†‚û™·µÅ·¥∑„Öï“âœâÂõõÂ§ß‚ú≥ƒèŒæŒª\\u200e√∞¬≤√∞¬∏√∞¬±√∞¬∏√±√∞¬∞√∞¬π√±√∞¬µ‚óä‚Üí‚Üí‚Üí‰Ωèÿ≠ÿ®ŸÑÿß¬°¬°¬°√º„É∂‚ùî‚¨á‡´ê◊ê◊ï◊ô◊ò◊ê◊†◊ê◊û◊¢√≠√Æ√¢√®√∑√™√†√¨·¥á”π ãÔΩÑÔΩíÔΩÅÔΩáÔΩèÔΩé‚Çô‚ôû…ôÀà‘âÃ∏œÜ‚ô•‚òº‚ô•«îƒùÊù®Áõä·à≥·ã≠·àò·å£Ôºç„Äê\\u200b\\u200b\\u200b…ê…Ø‚Ñ¨‚Öú·∏•ƒÅ‚Åª√∞¬∏‚ï≠‚à©‚ïÆÔ∏∂Ô∏øÔ∏∂‚ï≠‚à©‚ïÆ·¥≥ŸäŸàÿ¨ÿØ¬≤‚Å∞‚à†√∞¬¥√∞¬∞√±√±∆íÔºû·ö¢·ö±·õÅŸÜŸéŸéŸÅŸäÿØŸÑÿØÿ°ŸÑŸÑŸÑÿßŸàÿ¥ÿ±ŸÉ“ì”ôÔΩéÔΩèÔΩî…¥·¥è·¥õ√∞¬∑√∞¬∞√∞¬ø√±∆í√±√∞¬∫‚ô°‚ô•ÃöÕ©ÕõÕ´Õ¨ÃçÃãÕúÃ®ÕÄÕô\\u200b\\u206d‚òª”©‚ûûÿ±ÿßÿ¶ÿ≠ÿ©‚à†¬∞Õ≠ÃíÕ≠Õ£ÃûÃüÃ´Ã∫‚ú™‚àí‚àû‚àí‚àí‚àí‚àí‚àí‚àí‚àí„É≥“ì·¥è…¥·¥õ‚ãÅ¬¨¬¨‚ÇÇ‚ÜëÃΩÃàÃàÃåÕúÃôÃ≥ÃºÃ∫Ã∞ÔΩÑÔΩÅÔΩóÔΩé‚ùî‚ùì‚ùî‚ùì‚ùî‚ùì‚ùî‚ùì¬¨·É°·Éê·Éõ·É°·Éê·ÉÆ·É£·É†·Éò‚ùî‚ùî‚ùì‚ùì“ë‚ôõ‚â•√∞‚ôî∆ï‚ãÆ¬≤¬≤Êï£„Çâ„Åã„Åó„ÅüÂæå„Åç„Çå„ÅÑ„Å´„Åô„Çã„Åì„Å®„ÇíÂπ≥‰ªÆÂêç‰∫îÊñáÂ≠ó„Åß„ÅäÈ°ò„ÅÑ„Åó„Åæ„Åô„ÄÇÁøªË®≥ËÄÖÌîºÎìú ö‚ñÇ‚ñÉ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñàÔºüÕ™ÃàÃ´Ã†Ã±ÃóÕìÊ§éÊú®ÊÉÖœÄŒ¥ŒØÀê\\u200b\\u200b\\u206e“±“õ—ñ·êõÿØŸàÿ≥ÿ™ÔøºŒ∫Œ∫“£“ìÔøºÔøºÔøºÿ≤ÿßÿØ‚ô≠‚Ö± å—íÔΩÇÔΩÖÔΩìÔΩÖÔΩÑÔΩãÔΩÅÔΩÉÔΩàÔΩâÔΩåÔΩå‚âß·É†·ÉêÃ§◊°◊û◊ô—ï‡∏∑‡∏ß‚ïÆÃ∂Ã∂‚èÖ√∞¬ø√±‡Æú‡Øá‡ØÄ‡ØÇÎØº„âè‰øÑ‚äÇ„Éª„Éª‚äÉ‚úéÊÆãÈÖ∑œü‚îª‚îªÊ≥ΩÂæ∑„Éû‚î§‚ï§„Ç≤\\uf0b3œã„Öú„Öú‚ï§ÏÑ†ÏÉùÎãòÏù∏‡Ææ‡Æú‡ØÇ‡Æï‡Æ∏\\uf065‹Ω·ÉüÎ™©„Äî„Äï€§‡Æ∞Í≥°‚Çì‚úÇ·ÉØ‚õá◊ñ·Ω∑⁄Ø⁄Ø‚îúÌä∏Îü¨Î∏îÎ©îÏª§‚ô®‚Ö≤„Ç™‚ïêÁ•ûËã±„Äî€©€©…°‚¨ú‚¨õ‚¨ú‚¨õ‚¨ú‚¨õ‚¨ú‚¨õ‚¨ú‚¨ú‚¨õ‚¨ú‚¨õÕò»õÏò§ÏàòÎ°ú‚òòÂæóÊÑèÁõÆÊÄù„Ç¶‡§ï‡§∞‡•ç‡§£‚õé‚õé‚õéÍ∞ë÷∞÷¥÷∞‚ù™‚î¨‚î¥‚î¨‚î¥‚î§ÊìçÂ¶à‚óÜÊ±ùËæ∞ËçÄ‚äï‚ãÇÎã¨Î≥¥∆ç‚¨ú‚¨õ‚¨ú‚¨õ‚¨õ‚¨ú‚¨õ‚¨ú‚¨õ‚¨ú‚¨õ‚¨ú‚¨õ‚¨ú‚¨õ‚¨ú‚ö†ƒó÷¥÷∞÷∂‚ãÜ€£€ú„Å≥ÈáëÊØíÈú∏‚ïîÏù∏Ë™çË®º„Ç≠„Ç£ÂÜôÂÉèÊûöÊï∞Êº¢Êï∞Í∏∞ÎùºÍ≤åÏóÜ‡Ææ‡Æ∞‡ØåÈù©ÂëΩ„Ç¨\\uf054‚áÜ‚î≥‚î≥‚áì‚áì‚áìÊã•Â∞§ÁëãÊØÖ‡¶πÎäêÎÇåÃ¥›≤Â§¢ÊÉ≥‡ØÇ‡Æµ‡ÆïÏö©Í∏∞ÏôÄ‡ØÇ„Éù„Éè\\x97‚Å∂Êà¶„ÄïÍ∞êÏÇ¨Ìï©Îãπ‡∫ô‡∫≤‡ªà‡∫ó‡∫Å‡∫≤‡∫¢‡∫≤‡ªâ‡∫ª‡∫à‡ªÄ‡∫∞‡∫û‡∫≤‡ªâ‡∫ÇÏï®Î≤îÌä∏ÂÑ™ÀôÎ≠êÏòà…≤„ÅëŸåÏùåÌôÄÎ¶≠\\ue80a„Ç≠Ï¢ÖÏÑù‚ïπ‚ïπÈà¥Ë±™’π‚òâ‚öõ‚îú‚î¨‚î¥‚î¨‚î¥„Ç¶„Ç©«Å«É‚ô¢ÏßÄÏÑ∏Í∏çÏïàÔΩ∂ÔΩ¥ÔæôÂÑ™„ÅíÏù∏ÎÇ¥„Åà„Åà‚á©Î∞©ÌÉÑÎÖÑÎã®Áã¨ËßíÂÖΩÂéªÂêß‚éìÂëÄ‡∏Ö‡∏Ö\\uf8ff‚ó¨ÎåÄÎßå·∏±‡Æµ‡ØÄ‡Æ∞‡Æπ„Öã„Öã„ÖãËø∑ÊÄù‡Øá‡Øá‡Øá‡Øá‡Øá‡Øá‡ØáÎåÄÎ°ú«πË¨õÂ∫ß‰ºö„ÇÆ„É®…í\\ue4c7\\ue0f0\\uf1e2\\ue2f2\\ue9f3\\ue5f2\\ueecf\\ue0e6\\uf3eb\\uf1e9\\ue0f2\\ueee4\\ue0e1Ô≥¢\\ue5f2\\uec20\\uede5\\u20ff‚É¢\\ueff1\\uf1e8\\ueaee\\ue220\\uf8e0\\uf5e8\\uea20\\uedee\\ue0f2\\uf2ea\\ue2eeÈ¶ÆËé´Ï†ïÏßÑÎ¨∏ÿ§⁄©Îäê«Ä‡ØÄ‡ØÄ‡Æ∞‡ØáÁµêÈõ™Ìå¨ÎØ∏ÌåÖ◊¥·∫ø‡§≤‡•ã‡§Æ‡§æ‡§®‡•ç‡§•‡§æ‡§ô„ÉΩ‚Çπ‚ô§ÂèØ‰ª•ÂïèÈ°åÁèçË≤¥ÌïôÏÉùÏù∏Ïù∏Îç∞ û]','', text)\n",
    "    text = re.sub(r'[a-z]+yandexru|[a-z]+mailru|[a-z]+gmailcom|ramblerru|https?[a-z]+|www[a-z]+|[a-z]+com\\s|[a-z]+png|[a-z]+jpg', '', text)\n",
    "    \n",
    "    words = [word for word in word_tokenize(text)]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['norm'] = df['question'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_trash(text):\n",
    "    trash = re.findall(r'[^–∞-—èa-z—ë|\\s|-]+', str(text))\n",
    "    if trash:\n",
    "        return trash\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trash'] = df['norm'].apply(find_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trash = df[df.trash.notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "fast_text = FastText([text.split(' ') for text in df['norm']], size=300,window=8, min_n=2,\n",
    "                                   max_n=8, sorted_vocab=1,negative=10, iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_text.wv.most_similar('–ø—É—Ç–∏–Ω')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'fasttext_new.model'\n",
    "fast_text.save(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'fasttext_new.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from nltk.tokenize import word_tokenize, wordpunct_tokenize\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['trash'] = train['norm'].apply(find_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['trash'] = test['norm'].apply(find_trash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash = []\n",
    "for i in test['trash']:\n",
    "    if i:\n",
    "        trash += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash = list(set(trash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train['trash']:\n",
    "    if i:\n",
    "        trash += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash = list(set(trash))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash_str = ''\n",
    "for i in trash:\n",
    "    trash_str += i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trash_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['norm'] = train['question'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['norm'] = test['question'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['tokens'] = train['norm'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r''[^–ê-–Ø–∞-—è.!? ]', ' ',  text)\n",
    "    words = wordpunct_tokenize(text.lower())\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['tokens'] = test['norm'].apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_words = []\n",
    "for sent in words:\n",
    "    for word in sent:\n",
    "        if not word in model.wv.vocab:\n",
    "            unk_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vector  = np.zeros(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastText.load(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unknown_words = []\n",
    "for word in tqdm(train_list):\n",
    "    vector = model.wv[word]\n",
    "    comparison = np.array_equal(vector, zero_vector)\n",
    "    if comparison:\n",
    "        unknown_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(test['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list(train['tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listmerge3(lstlst):\n",
    "    all_list=[]\n",
    "    for lst in lstlst:\n",
    "          all_list.extend(lst)\n",
    "    return all_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test=listmerge3(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_list = list(set(list_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test=listmerge3(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list(set(train_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = train_list + test_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = list(set(data_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {'PAD' : 0}\n",
    "for word in data_list:\n",
    "    word2index[word] = len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordData(Dataset):\n",
    "    \n",
    "    def __init__(self, x_data, y_data, word2index, sequence_length=32, pad_token='PAD', verbose=True):\n",
    "        \n",
    "        super().__init__()\n",
    "        \n",
    "        self.x_data = []\n",
    "        self.y_data = y_data\n",
    "        self.ft = model.wv\n",
    "        \n",
    "        self.word2index = word2index\n",
    "        self.sequence_length = sequence_length\n",
    "        \n",
    "        self.pad_token = pad_token\n",
    "        self.pad_index = self.word2index[self.pad_token] #here is 0\n",
    "        \n",
    "        self.load(x_data, verbose=verbose)\n",
    "        \n",
    "    @staticmethod\n",
    "    def process_text(text):\n",
    "        \n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r''[^–ê-–Ø–∞-—è.!? ]', ' ',  text)\n",
    "        \n",
    "        words = wordpunct_tokenize(text.lower())\n",
    "        \n",
    "        return words\n",
    "        \n",
    "    def load(self, data, verbose=True):\n",
    "        \n",
    "        data_iterator = tqdm(data, desc='Loading data', disable=not verbose)\n",
    "        \n",
    "        for text in data_iterator:\n",
    "            \n",
    "            words = self.process_text(text)\n",
    "            \n",
    "            indexed_words = self.indexing(words)\n",
    "            \n",
    "            self.x_data.append(indexed_words)\n",
    "    \n",
    "    def indexing(self, tokenized_text):\n",
    "\n",
    "        # –∑–¥–µ—Å—å –º—ã –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–∫–µ–Ω UNK, –ø–æ—Ç–æ–º—É —á—Ç–æ –º—ã –º—ã –µ–≥–æ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –Ω–µ —É—á–∏–ª–∏\n",
    "        # —Å—Ç–∞–Ω–æ–≤–∏—Ç—Å—è –Ω–µ–ø–æ–Ω—è—Ç–Ω–æ –∫–∞–∫–æ–π –∂–µ —ç–º–±–µ–¥–¥–∏–Ω–≥ –ø—Ä–∏—Å–≤–æ–∏—Ç—å –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ–º—É —Å–ª–æ–≤—É,\n",
    "        # –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ –≤—ã–±—Ä–∞—Å—ã–≤–∞–µ–º –Ω–∞—à–∏ –Ω–µ–∏–∑–≤–µ—Ç—Å–Ω—ã–µ —Å–ª–æ–≤–∞\n",
    "                \n",
    "        return [self.word2index[token] for token in tokenized_text if token in self.word2index]\n",
    "                \n",
    "    \n",
    "    def padding(self, sequence):\n",
    "        \n",
    "        # –û–≥—Ä–∞–Ω–∏—á–∏—Ç—å –¥–ª–∏–Ω—É self.sequence_length\n",
    "        sequence_length = self.sequence_length\n",
    "        \n",
    "        if len(sequence) > sequence_length:\n",
    "            sequence = sequence[:sequence_length] \n",
    "            \n",
    "        # –µ—Å–ª–∏ –¥–ª–∏–Ω–∞ –º–µ–Ω—å—à–µ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–π - –∑–∞–ø–∞–¥–∏—Ç—å\n",
    "        if len(sequence) < sequence_length:\n",
    "            sequence += (sequence_length - len(sequence))*[self.pad_index]\n",
    "                         \n",
    "        return sequence\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.x_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        x = self.x_data[idx]\n",
    "        x = self.padding(x)\n",
    "        x = torch.Tensor(x).long()\n",
    "\n",
    "        y = self.y_data[idx]\n",
    "        \n",
    "        return x, y\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_validation, y_train, y_validation = train_test_split(train.question, train.main_category, test_size=0.1)\n",
    "\n",
    "train_dataset = WordData(list(x_train), list(y_train), word2index)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64)\n",
    "\n",
    "validation_dataset = WordData(list(x_validation), list(y_validation), word2index)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=64)\n",
    "\n",
    "test_dataset = WordData(list(test.question), np.zeros((test.shape[0])), word2index)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in test_loader:\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = train.main_category.unique().shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2word = {}\n",
    "for key, value in word2index.items():\n",
    "    ind2word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index['—Ä—É–±–µ–Ω']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 300\n",
    "vectors = np.zeros((len(word2index), dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num in range(len(word2index)):\n",
    "    vector = model.wv[ind2word[num]]\n",
    "    vectors[num] = vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ind2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAverageNetwork(torch.nn.Module):\n",
    "    \n",
    "    # def __init__(self, embedding_matrix, n_classes):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, n_layers, n_classes, drop_prob=0.3):\n",
    "        \n",
    "        super().__init__()\n",
    "    \n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        #fasttext —ç–º–±–µ–¥–¥–∏–Ω–≥–∏\n",
    "        self.embedding = torch.nn.Embedding.from_pretrained(torch.Tensor(vectors))\n",
    "        \n",
    "\n",
    "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, n_layers, dropout=drop_prob, batch_first=True, bidirectional=True)\n",
    "        \n",
    "        self.hidden2label = torch.nn.Linear(hidden_dim*2, 32)\n",
    "        self.cnn_1 = torch.nn.Conv1d(in_channels=600, out_channels=300, kernel_size=2)\n",
    "        \n",
    "        self.cnn_2 = torch.nn.Conv1d(in_channels=600, out_channels=300, kernel_size=3)\n",
    "        \n",
    "        self.cnn_3 = torch.nn.Conv1d(in_channels=600, out_channels=300, kernel_size=4)\n",
    "        \n",
    "        self.cnn_4 = torch.nn.Conv1d(in_channels=600, out_channels=300, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(300, 128)\n",
    "        self.fc1_bn = torch.nn.BatchNorm1d(128)\n",
    "        self.fc2 = torch.nn.Linear(128, 28)\n",
    " \n",
    "        self.dropout = torch.nn.Dropout(p=0.3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        embeds = self.embedding(x)\n",
    "        #–ø—Ä—è—á–µ–º —á–∞—Å—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤\n",
    "#         embeds = self.dropout(embeds)\n",
    "        \n",
    "        #–∑–∞–ø–∞–∫–æ–≤—ã–≤–∞–µ–º \n",
    "        seq_lengths = torch.LongTensor(list(map(len, embeds)))\n",
    "        packed_embeds = torch.nn.utils.rnn.pack_padded_sequence(embeds, seq_lengths.cpu().numpy(), batch_first=True, enforce_sorted=False)\n",
    "        \n",
    "        #–ø–æ–¥–∞—ë–º –≤ lstm\n",
    "        lstm_packed_output, _ = self.lstm(packed_embeds)\n",
    "        #—Ä–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º\n",
    "        lstm_out, _ = torch.nn.utils.rnn.pad_packed_sequence(lstm_packed_output, batch_first=True)\n",
    "    \n",
    "#         #—Ç—Ä–∞–Ω—Å–ø–æ–Ω–∏—Ä—É–µ–º, —á—Ç–æ–±—ã –ø–µ—Ä–µ–¥–∞—Ç—å –≤ cnn\n",
    "        transposed_lstm_out = lstm_out.transpose(1,2)\n",
    "\n",
    "        #–¥–æ–±–∞–≤–ª—è–µ–º 4 –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω—ã–µ —Å–≤—ë—Ä—Ç–∫–∏ –∏ –ø—É–ª–∏–Ω–≥–∏ –∫ –Ω–∏–º\n",
    "        cnn_1 = F.relu(self.cnn_1(transposed_lstm_out)) \n",
    "        maxpool_1 = torch.nn.MaxPool1d(kernel_size=cnn_1.shape[2])\n",
    "        maxpool1_out = maxpool_1(cnn_1)\n",
    "        \n",
    "        cnn_2 = F.relu(self.cnn_2(transposed_lstm_out))\n",
    "        maxpool_2 = torch.nn.MaxPool1d(kernel_size=cnn_2.shape[2])\n",
    "        maxpool2_out = maxpool_2(cnn_2)\n",
    "        \n",
    "        cnn_3 = F.relu(self.cnn_3(transposed_lstm_out))\n",
    "        maxpool_3 = torch.nn.MaxPool1d(kernel_size=cnn_3.shape[2])\n",
    "        maxpool3_out = maxpool_3(cnn_1)\n",
    "        \n",
    "        cnn_4 = F.relu(self.cnn_4(transposed_lstm_out))\n",
    "        maxpool_4 = torch.nn.MaxPool1d(kernel_size=cnn_4.shape[2])\n",
    "        maxpool4_out = maxpool_4(cnn_4)\n",
    "        \n",
    "        –∫–æ–Ω–∫–∞—Ç–µ–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã\n",
    "        cnn_out =  torch.cat([maxpool1_out, maxpool2_out, maxpool3_out, maxpool4_out], 2)\n",
    "        \n",
    "        pred = cnn_out.transpose(1, 2)\n",
    "        \n",
    "        #–¥–≤–∞ –ª–∏–Ω–µ–π–Ω—ã—Ö —Å–ª–æ—è –Ω–∞ –≤—ã—Ö–æ–¥–µ\n",
    "        pred = transposed_lstm_out[-1]\n",
    "        print(pred.shape)\n",
    "        pred = self.fc2(F.relu(self.fc1_bn(self.hidden2label(pred))))\n",
    "        pred = F.relu(self.fc1_bn(self.fc1(pred[:, -1, :])))\n",
    "        \n",
    "        pred = self.fc2(pred)\n",
    "        pred = F.relu(pred)\n",
    "        \n",
    "        return pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(word2index) + 1\n",
    "embedding_dim = 300\n",
    "hidden_dim = 300\n",
    "n_layers = 2\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.005\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DeepAverageNetwork(vocab_size, embedding_dim, hidden_dim, n_layers, n_classes)\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_cached()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    torch.cuda.empty_cache()\n",
    "    x = x.to(device)\n",
    "    pred = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "losses = []\n",
    "best_test_loss = 10.\n",
    "\n",
    "test_f1 = []\n",
    "\n",
    "for n_epoch in range(epochs):\n",
    "    \n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    test_targets = []\n",
    "    test_pred_class = []\n",
    "    \n",
    "    progress_bar = tqdm_notebook(total=len(train_loader.dataset), desc='Epoch {}'.format(n_epoch + 1))\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        pred = model(x)\n",
    "        loss = criterion(pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        progress_bar.set_postfix(train_loss = np.mean(losses[-500:]))\n",
    "\n",
    "        progress_bar.update(x.shape[0])\n",
    "        \n",
    "    progress_bar.close()\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    for x, y in validation_loader:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            pred = model(x)\n",
    "\n",
    "            pred = pred.cpu()\n",
    "            y = y.cpu()\n",
    "\n",
    "            test_targets.append(y.numpy())\n",
    "            test_pred_class.append(np.argmax(pred, axis=1))\n",
    "\n",
    "            loss = criterion(pred, y)\n",
    "\n",
    "            test_losses.append(loss.item())\n",
    "        \n",
    "    mean_test_loss = np.mean(test_losses)\n",
    "\n",
    "    test_targets = np.concatenate(test_targets).squeeze()\n",
    "    test_pred_class = np.concatenate(test_pred_class).squeeze()\n",
    "\n",
    "    f1 = f1_score(test_targets, test_pred_class, average='micro')\n",
    "\n",
    "    test_f1.append(f1)\n",
    "    \n",
    "    print()\n",
    "    print('Losses: train - {:.3f}, test - {:.3f}'.format(np.mean(train_losses), mean_test_loss))\n",
    "\n",
    "    print('F1 test - {:.3f}'.format(f1))\n",
    "        \n",
    "    # Early stopping:\n",
    "    if mean_test_loss < best_test_loss:\n",
    "        best_test_loss = mean_test_loss\n",
    "    else:\n",
    "        print('Early stopping')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "predictions = []\n",
    "\n",
    "for x, _ in test_loader:\n",
    "\n",
    "    x = x.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        pred = model(x)\n",
    "\n",
    "        pred = pred.cpu()\n",
    "        \n",
    "        predictions.append(np.argmax(pred, axis=1))\n",
    "        \n",
    "predictions = np.concatenate(predictions).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['main_category'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['index', 'main_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
